---
title: Research Projects
excerpt: "An overview of my research projects"
toc-location: right
page-layout: full
---

Here you can find an overview of my current research projects. A list
of past research projects can be found at the [bottom of this page](#past-projects). 

## Real-Time Spatio-Temporal Data Analysis for Monitoring Logistics Networks {#abi-logistics}

![](../images/ABI_graph_data.png){width=100% fig-align="left" fig-alt="An illustration of amortized Bayesian inference for graph data."}

In complex logistics and supply chain networks, the acquisition of tracking data representing the
flow of entities through the networks has become state of the art. 
The goal of
tracking entities is to improve transparency and predict the state of the network. An important
value for operations is the estimated time of arrival of entities at different nodes of the network.
The respective business goal determines the requirements for the forecasting procedure: it might
be necessary to detect a delay in a container ship transport as early as possible (weeks before
the arrival) to be able to send a replacement for urgent parts by air. Or it might be necessary to
predict the arrival of trucks within the next hour as accurately as possible to manage the traffic
at logistics sites. However, acquiring data is costly in terms of money, energy used by sensors,
and required IT infrastructure. 

In this project, we will develop new methods for predicting
arrival times in complex logistics networks (e.g., multi-modal transport networks). 
Our methods will enable (a) the integration of different data types,
e.g., event, weather, and tracing data, (b) the ability to cope with changes in the underlying
logistics network in real-time, and (c) the ability to communicate uncertainty in predictions,
especially in case of tracing data or weather forecasts of limited reliability. 

This project is part of the [Collaborative Research Center 391](https://trr391.tu-dortmund.de/) funded by the German Research Foundation.

Overarching Topics: 
[Amortized Inference](../research#abi){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Uncertainty Quantification](../research#uncertainty-quantification){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Project Members: 
[Svenja Jedhoff](../people#svenja-jedhoff){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funders: 
[German Research Foundation (DFG)](https://www.dfg.de/en/index.jsp){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[TU Dortmund University](https://www.tu-dortmund.de/en/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funding Period: 2024 -- 2028

Publications:

- **Jedhoff S.**, Kutabi H., Meyer A. & Bürkner P. C. (in review). Efficient Uncertainty Propagation in Bayesian Two-Step Procedures. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2505.10510){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/sjedhoff/efficient-2step-uncertainty-paper){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

<!-- -->

## Semi-Supervised Learning for Robust Amortized Bayesian Inference

![](../images/self_consistency_posterior_contour.png){width=100% fig-align="left" fig-alt="Results obtained from semi-supervised ABI training."}

Amortized Bayesian inference (ABI) with neural networks can solve probabilistic inverse problems orders of magnitude faster than classical methods. However, ABI is not yet sufficiently robust for widespread and safe application. When performing inference on observations outside the scope of the simulated training data, posterior approximations are likely to become highly biased, which cannot be adequately corrected just by additional simulations.

In this project, we work on semi-supervised approaches that enable training not only on labeled simulated data generated from the model, but also on \textit{unlabeled} data originating from any source, including real-world data. We hypothesize that such approaches can strongly increase estimation accuracy and robustness especially for real-world data outside of the immediate simulation scope.

Overarching Topics: 
[Amortized Inference](../research#abi){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Uncertainty Quantification](../research#uncertainty-quantification){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Project Members: 
[Aayush Mishra](../people#aayush-mishra){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funders: 
[TU Dortmund University](https://www.tu-dortmund.de/en/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funding Period: 2024 -- 2027

Publications:

- **Mishra A.**, Habermann D., Schmitt M., Radev S. T., & Bürkner P. C. (in review). Robust Amortized Bayesian Inference with Self-Consistency Losses on Unlabeled Data. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2501.13483){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- Kucharský Š., **Mishra A.**, Habermann D., Radev S. T., & Bürkner P. C. (in review). Improving the Accuracy of Amortized Model Comparison with Self-Consistency. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2512.14308){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- Kucharský Š., **Mishra A.**, Habermann D., Radev S. T., & Bürkner P. C. (2025). Towards Trustworthy Amortized Bayesian Model Comparison. *NeurIPS Workshop on Reliable Machine Learning from Unreliable Data*.
[PDF](pdf/2025__Kucharsky_et_al__NeurIPS_Workshop_Reliable_ML.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2508.20614){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}


<!-- -->

## BayesFlow: Simulation Intelligence with Deep Learning {#bayesflow-software}

![](../images/bayesflow_overview.png){width=80% fig-align="left" fig-alt="An illustration of the Bayesflow framework."}

Simulation intelligence (SI) subsumes an emerging generation of scientific methods which utilize digital simulations for emulating and understanding complex real-world systems and phenomena. Recently, neural networks and deep learning have demonstrated a great potential for accelerating and scaling up SI to previously intractable problems and data sets. However, the availability of user-friendly software is still limited, which hampers the widespread and flexible use of modern SI methods. 

In this project, we focus on software for amortized Bayesian inference, which is an essential part of SI. The hallmark feature of amortized Bayesian inference is an upfront training phase (e.g., of a neural network), which is then amortized by a nearly instant fully Bayesian inference for an arbitrary number of data sets during test time. Concretely, we aim to advance the [BayesFlow research software library](../software#bayesflow) into becoming the long-term, gold-standard software for amortized Bayesian inference. 

Overarching Topics: 
[Amortized Inference](../research#abi){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Machine-Assisted Workflows](../research#machine-workflow){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Uncertainty Quantification](../research#uncertainty-quantification){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Project Members: 
[Lars Kühmichel](../people#lars-kuehmichel){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funders: 
[German Research Foundation (DFG)](https://www.dfg.de/en/index.jsp){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funding Period: 2024 -- 2027

Publications:

- Bracher N., **Kühmichel L.**, Ivanova D. R., Intes X., Bürkner P. C., & Radev S. T. (in review). JADAI: Jointly Amortizing Adaptive Design and Bayesian Inference. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2512.22999){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- Müller, J., **Kühmichel, L.**, Rohbeck, M., Radev, S. T., & Köthe, U. (in review). Towards Context-Aware Domain Generalization: Understanding the Benefits and Limits of Marginal Transfer Learning. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2312.10107){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs} 

- Habermann D., Schmitt M., **Kühmichel L.**, Bulling A., Radev S. T., & Bürkner P. C. (2025). Amortized Bayesian Multilevel Models. *Bayesian Analysis*. doi:10.1214/25-BA1570
[PDF](../publications/pdf/2025__Habermann_et_al__Bayesian_Analysis.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Journal](https://projecteuclid.org/journals/bayesian-analysis/advance-publication/Amortized-Bayesian-Multilevel-Models/10.1214/25-BA1570.full){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2408.13230){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- Pogorelyuk, L., Bracher, N. L., Verkleeren, A., **Kühmichel, L.**, & Radev, S. T. (2025). Stable Single-Pixel Contrastive Learning for Semantic and Geometric Tasks. *NeurIPS Workshop on Unifying Representations in Neural Models*.
[Conference](https://openreview.net/forum?id=nzGuDABwce){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/stefanradev93/oxels){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

<!-- -->

## Applications of Amortized Bayesian Inference {#abi-applications}

![](../images/mixture_networks_forward.png){width=80% fig-align="left" fig-alt="An illustration of amortized mixture models." fig-align="left"}

Recent developments in simulation-based amortized inference have ushered in new possibilities for conducting principled Bayesian analysis. The simulation-based approach unlocks the potential of complex models whose likelihoods or priors are not analytically tractable. Amortized approaches make the required computations relatively fast, thus allowing for the deployment of intricate models in scenarios that were hitherto deemed unfeasible or inconvenient. 
Nevertheless, the novelty of this approach poses a challenge, as its widespread adoption hinges on the availability of user-friendly documentation and resources that simplify entry into the field, as well as empirical examples that validate the method’s usefulness for the practical researchers.

In this project, our emphasis is on applications within cognitive modeling and developmental psychology. We focus on how simulation-based amortized inference can address important challenges within the field, not only during the data analysis phase but also in the planning and execution of studies and experiments. As a by-product we will generate tutorials and educational materials providing gentle introductions into the topic. This project also aims to lay the foundations for integrating simulation-based amortized inference with popular statistical software packages used by practitioners who may not have extensive coding skills, thereby broadening the scope of users benefiting from its advantages.

Overarching Topics: 
[Amortized Inference](../research#abi){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Latent Variable Modeling](../research#lvm){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Uncertainty Quantification](../research#uncertainty-quantification){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Project Members: 
[Šimon Kucharský](../people#simon-kucharsky){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funders: 
[TU Dortmund University](https://www.tu-dortmund.de/en/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funding Period: 2024 -- 2027

Publications:

- **Kucharský Š.** & Bürkner P. C. (in review). Amortized Bayesian Mixture Models. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2501.10229){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Kucharský Š.**, Mishra A., Habermann D., Radev S. T., & Bürkner P. C. (in review). Improving the Accuracy of Amortized Model Comparison with Self-Consistency. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2512.14308){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Kucharský Š.**, Mishra A., Habermann D., Radev S. T., & Bürkner P. C. (2025). Towards Trustworthy Amortized Bayesian Model Comparison. *NeurIPS Workshop on Reliable Machine Learning from Unreliable Data*.
[PDF](pdf/2025__Kucharsky_et_al__NeurIPS_Workshop_Reliable_ML.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2508.20614){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Kucharský Š.** & Bürkner P. C. (2025). Amortized Bayesian Cognitive Modeling with BayesFlow. *PsyArXiv preprint*. doi:10.31234/osf.io/34k6q_v1
[Preprint](https://osf.io/preprints/psyarxiv/34k6q_v1){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Website](https://kucharssim.github.io/bayesflow-cognitive-modeling-book/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/Kucharssim/bayesflow-cognitive-modeling-book){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}


## Amortized Bayesian Inference for Multilevel Models {#amortized-mlms}

![](../images/mlm_overview.png){fig-alt="An illustration of amortized multilevel models." fig-align="left"}

Probabilistic multilevel models (MLMs) are a central building block in Bayesian data analysis. Despite their widely acknowledged advantages, MLMs remain challenging to estimate and evaluate, especially when the involved likelihoods or priors are analytically intractable. Recent developments in generative deep learning and simulation-based inference have shown promising results in scaling up Bayesian inference through amortization. However, the utility of deep generative models for learning Bayesian MLMs remains largely unexplored.

In this project, we propose to develop a general and efficient neural inference framework for estimating and evaluating complex Bayesian MLMs. Our framework will substantially extend previous work on simulation-based Bayesian inference for single-level models. Moreover, it aims to encompass not only the inference phase of a Bayesian workflow but also the model evaluation steps, which usually comprise a computational bottleneck with standard (non-amortized) Bayesian methods. Thus, the proposed project has the potential to greatly enhance model-based inference and understanding of complex processes across the quantitative sciences.

Overarching Topics: 
[Amortized Inference](../research#abi){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Latent Variable Modeling](../research#lvm){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Uncertainty Quantification](../research#uncertainty-quantification){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Project Members: [Daniel Habermann](../people#daniel-habermann){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funders: 
[German Research Foundation (DFG)](https://www.dfg.de/en/index.jsp){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[TU Dortmund University](https://www.tu-dortmund.de/en/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funding Period: 2023 -- 2026

Publications:

- Mishra A., **Habermann D.**, Schmitt M., Radev S. T., & Bürkner P. C. (in review). Robust Amortized Bayesian Inference with Self-Consistency Losses on Unlabeled Data. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2501.13483){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- Kucharský Š., Mishra A., **Habermann D.**, Radev S. T., & Bürkner P. C. (in review). Improving the Accuracy of Amortized Model Comparison with Self-Consistency. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2512.14308){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- Kucharský Š., Mishra A., **Habermann D.**, Radev S. T., & Bürkner P. C. (2025). Towards Trustworthy Amortized Bayesian Model Comparison. *NeurIPS Workshop on Reliable Machine Learning from Unreliable Data*.
[PDF](pdf/2025__Kucharsky_et_al__NeurIPS_Workshop_Reliable_ML.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2508.20614){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Habermann D.**, Schmitt M., Kühmichel L., Bulling A., Radev S. T., & Bürkner P. C. (2025). Amortized Bayesian Multilevel Models. *Bayesian Analysis*. doi:10.1214/25-BA1570
[PDF](../publications/pdf/2025__Habermann_et_al__Bayesian_Analysis.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Journal](https://projecteuclid.org/journals/bayesian-analysis/advance-publication/Amortized-Bayesian-Multilevel-Models/10.1214/25-BA1570.full){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2408.13230){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- Schmitt M., Ivanova D. R., **Habermann D.**, Köthe U., Bürkner P. C., & Radev S. T. (2024). Leveraging Self-Consistency for Data-Efficient Amortized
Bayesian Inference. *Proceedings of the International Conference on Machine Learning (ICML)*.
[PDF](../publications/pdf/2024__Schmitt_et_al__ICML.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Conference](https://openreview.net/forum?id=uoUOz427RD){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2310.04395){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

<!-- -->

## Bayesian Distributional Latent Variable Models {#bdlvms}

![](../images/distributional_SEMs.png){fig-alt="An illustration of distributional SEMs." fig-align="left"}

In psychology and related sciences, a lot of research is concerned with studying
latent variables, that is, constructs which are not directly observable.
Statistical methods for modeling latent variables based on manifest (observable)
indicators are thus crucial to the scientific progress in those fields. Two
major interconnected statistical areas dealing with latent variables exist,
namely, Item Response Theory (IRT) and Structural Equation Modeling (SEM).
Although the two fields are closely connected, the frontiers of IRT and SEM have
developed in somewhat different directions.

A combination of these two major frontiers would enable researchers to tackle a
lot of advanced psychological research questions at the intersection of
psychometrics, personnel psychology, cognitive psychology, and applied
psychology. In order for us to gain better insights into behavioral and
cognitive processes, their mathematical approximations should match the
processes' complexity in both overall distributional form and its components
that are expressed as complex functions of predicting variables.

This project aims to develop a framework for Bayesian distributional latent
variable models that combines the principles of IRT and SEM with the flexibility
of distributional regression powered by modern Bayesian estimation methods.

Overarching Topics: 
[Latent Variable Modeling](../research#lvm){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Machine-Assisted Workflows](../research#machine-workflow){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Uncertainty Quantification](../research#uncertainty-quantification){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Project Members: [Luna Fazio](../people#luna-fazio){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funders: 
[German Research Foundation (DFG)](https://www.dfg.de/en/index.jsp){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[TU Dortmund University](https://www.tu-dortmund.de/en/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funding Period: 2022 -- 2025

Publications:

- **Fazio L.**, Scholz M., Aguilar J. E., & Bürkner P. C. (in review). Primed Priors for Simulation-Based Validation of Bayesian Models. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2408.06504){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/sims1253/implicit-priors){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Fazio L.** & Bürkner P. C. (2025). Gaussian distributional structural equation models: A framework for modeling latent heteroscedasticity. *Multivariate Behavioral Research*. doi:10.1080/00273171.2025.2483252
[PDF](../publications/pdf/2025__Fazio_Buerkner__Multivariate_Behavioral_Research.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Journal](https://www.tandfonline.com/doi/full/10.1080/00273171.2025.2483252){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2404.14124){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/bdlvm-project/gdsem-paper){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

<!-- -->

## Simulation-Based Prior Distributions for Bayesian Models {#sbpriors}

![](../images/simulation-based-priors.png){fig-alt="An illustration of the simulation-based prior workflow." fig-align="left"}

Data-driven statistical modeling plays a crucial role in almost all quantitative
sciences. Despite continuous increases in the amount of available data, the
addition of further information sources, such as expert knowledge, often remains
an irreplaceable part of setting up high-fidelity models. Grounded in
probability theory, Bayesian statistics provides a principled approach to
including expert knowledge in the form of prior distributions, a process called
prior elicitation. However, prior elicitation for high-dimensional Bayesian
models is infeasible with existing methods due to practical and computational
challenges. With the goal of solving these challenges, we propose to develop
simulation-based priors for high-dimensional Bayesian models that allow to
incorporate prior information elicited on any model-implied quantities. We
expect the developed methods to have a major impact on all fields applying
probabilistic modeling by making the use of expert knowledge practical, robust,
and computationally feasible.

Overarching Topics: 
[Prior Specification](../research#prior-specification){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Amortized Inference](../research#abi){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Uncertainty Quantification](../research#uncertainty-quantification){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Project Members: [Florence Bockting](../people#florence-bockting){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funders: [TU Dortmund University](https://www.tu-dortmund.de/en/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Cluster of Excellence SimTech](https://www.simtech.uni-stuttgart.de/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funding Period: 2022 -- 2025

Publications: 

- **Bockting F.** & Bürkner P. C. (in review). elicito: A Python Package for Expert Prior Elicitation. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2506.16830){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Software](https://github.com/florence-bockting/elicito){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Bockting F.**, Radev S. T., & Bürkner P. C. (2025). Expert-elicitation method for non-parametric joint priors using normalizing flows. *Statistics and Computing*. doi:0.1007/s11222-025-10665-z
[PDF](../publications/pdf/2025__Bockting_et_al__Statistics_and_Computing.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Journal](https://link.springer.com/article/10.1007/s11222-025-10665-z){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2411.15826){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code](https://github.com/florence-bockting/prior_elicitation/tree/main/elicit/manuscript_non_parametric_joint_prior){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Data](https://osf.io/xrzh6/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Bockting F.**, Radev S. T., & Bürkner P. C. (2024). Simulation-Based Prior Knowledge Elicitation for Parametric Bayesian Models. *Scientific Reports*. doi:10.1038/s41598-024-68090-7
[PDF](../publications/pdf/2024__Bockting_et_al__Scientific_Reports.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Journal](https://www.nature.com/articles/s41598-024-68090-7){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](http://arxiv.org/abs/2308.11672){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/florence-bockting/PriorLearning){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

<!-- -->

## Probabilistic Models for Single-Cell RNA Sequencing Data {#scrna-models}

![](../images/latent-derivative-gps.png){fig-alt="An illustration of our latent derivative Gaussian process framework." fig-align="left"}

Trajectory and pseudo-time inference methods in single-cell RNA sequencing face
challenges from the ambiguity of the static single-cell transcriptome snapshot
data. In this project, we aim to tackle this challenge by means of advanced
probabilistic methods. Concretely, we aim to reconstruct unobserved cell
ordering as latent pseudo-time by analyzing RNA spliced counts and corresponding
derivative RNA velocity. Further, we aim to obtain uncertainty estimates of the
latent cell ordering using Bayesian inference. To achieve these goals, we will
develop advanced latent Gaussian process models with the ability of utilizing
derivative information to increase precision in estimating unobserved latent
inputs. This model deploys derivative covariance kernel functions and
modifications in the hyperparameter specifications, thus increasing capabilities
for utilizing derivative information in a multi-output setting. Although the
primary motivation lies in applications in single-cell biology, this model has
the potential to solve similar research problems dealing with multi-output data
and its derivatives from diverse fields of study.

Overarching Topics: 
[Latent Variable Modeling](../research#lvm){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Uncertainty Quantification](../research#uncertainty-quantification){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Project Members: [Soham Mukherjee](../people#soham-mukherjee){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Co-Supervisors: [Manfred Claassen](https://claassenlab.github.io/people/manfred-claassen/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funders: 
[TU Dortmund University](https://www.tu-dortmund.de/en/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[University of Tübingen](https://uni-tuebingen.de/en/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funding Period: 2022 -- 2025

Publications:

- **Mukherjee S.**, Aguilar J. E., Zago M., Claassen M., & Bürkner P. C. (in review). Latent variable estimation with composite Hilbert space Gaussian processes. *ArXiv preprint*. 
[Preprint](https://arxiv.org/abs/2510.25371){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/Soham6298/Latent-Composite-HSGPs){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Mukherjee S.**, Claassen M., & Bürkner P. C. (in review). Hilbert space methods for approximating multi-output latent variable Gaussian processes. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2505.16919){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/Soham6298/Latent-variable-HSGPs){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Mukherjee S.**, Claassen M., & Bürkner P. C. (2025). DGP-LVM: Derivative Gaussian process latent variable models. *Statistics and Computing*. doi:10.1007/s11222-025-10644-4
[PDF](../publications/pdf/2025__Mukherjee_et_al__Statistics_and_Computing.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Journal](https://link.springer.com/article/10.1007/s11222-025-10644-4){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2404.04074){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/Soham6298/DGP-LVM){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

<!-- -->

## Intuitive Joint Priors for Bayesian Multilevel Models {#joint-priors-mlms}

![](../images/coef_r2d2_marginal.png){fig-alt="Marginal densities of the R2D2 prior's coefficients."}

Regression models are ubiquitous in the quantitative sciences making up a big
part of all statistical analysis performed on data. In the quantitative
sciences, data often contains multilevel structure, for example, because of
natural groupings of individuals or repeated measurement of the same
individuals. Multilevel models (MLMs) are designed specifically to account for
the nested structure in multilevel data and are a widely applied class of
regression models. From a Bayesian perspective, the widespread success of MLMs
can be explained by the fact that they impose joint priors over a set of
parameters with shared hyper-parameters, rather than separate independent priors
for each parameter. However, in almost all state-of-the-art approaches,
different additive regression terms in MLMs, corresponding to different
parameter sets, still receive mutually independent priors. As more and more
terms are being added to the model while the number of observations remains
constant, such models will overfit the data. This is highly problematic as it
leads to unreliable or uninterpretable estimates, bad out-of-sample predictions,
and inflated Type I error rates.

To solve these challenges, this project aims to develop, evaluate, implement,
and apply intuitive joint priors for Bayesian MLMs. We hypothesize that our
developed priors will enable the reliable and interpretable estimation of much
more complex Bayesian MLMs than was previously possible.

Overarching Topics: 
[Prior Specification](../research#prior-specification){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Uncertainty Quantification](../research#uncertainty-quantification){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Project Members: [Javier Aguilar](../people#javier-aguilar){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funders: 
[German Research Foundation (DFG)](https://www.dfg.de/en/index.jsp){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[TU Dortmund University](https://www.tu-dortmund.de/en/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[University of Stuttgart](https://www.uni-stuttgart.de/en/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funding Period: 2021 -- 2025

Publications:

- **Aguilar J. E.** & Bürkner P. C. (in review). Dependency-Aware Shrinkage Priors for High Dimensional Regression.  *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2505.10715){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://osf.io/fuean/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Aguilar J. E.**, Kohns D., Vehtari A., & Bürkner P. C. (in review). R2 priors for Grouped Variance Decomposition in High-dimensional Regression. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2507.11833){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/jear2412/GroupR2priors){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- Fazio L., Scholz M., **Aguilar J. E.**, & Bürkner P. C. (in review). Primed Priors for Simulation-Based Validation of Bayesian Models. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2408.06504){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/sims1253/implicit-priors){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- Mukherjee S., **Aguilar J. E.**, Zago M., Claassen M., & Bürkner P. C. (in review). Latent variable estimation with composite Hilbert space Gaussian processes. *ArXiv preprint*. 
[Preprint](https://arxiv.org/abs/2510.25371){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/Soham6298/Latent-Composite-HSGPs){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Aguilar J. E.** & Bürkner P. C. (2025). Generalized Decomposition Priors on R2. *Bayesian Analysis*. doi:10.1214/25-BA1524
[PDF](../publications/pdf/2025__Aguilar_Buerkner__Bayesian_Analysis.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Journal](https://projecteuclid.org/journals/bayesian-analysis/advance-publication/Generalized-Decomposition-Priors-on-R2/10.1214/25-BA1524.full){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2401.10180){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://osf.io/ns2cv/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs} 

- Reiser P., **Aguilar J. E.**, Guthke A., & Bürkner P. C. (2025). Uncertainty Quantification and Propagation in Surrogate-based Bayesian Inference. *Statistics and Computing*. doi:10.1007/s11222-025-10597-8
[PDF](../publications/pdf/2025__Reiser_et_al__Statistics_and_Computing.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Journal](https://link.springer.com/article/10.1007/s11222-025-10597-8){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2312.05153){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/philippreiser/bayesian-surrogate-uncertainty-paper){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Aguilar J. E.** & Bürkner P. C. (2023). Intuitive Joint Priors for Bayesian Linear Multilevel Models: The R2D2M2 prior. *Electronic Journal of Statistics*. doi:10.1214/23-EJS2136
[PDF](../publications/pdf/2023__Aguilar_Bürkner__Electronic_Journal_of_Statistics.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Journal](https://doi.org/10.1214/23-EJS2136){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2208.07132){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://osf.io/wgsth/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Talk](../talks/pdf/poster_R2D2M2_prior.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

<!-- -->

<br /> 
<br /> 

## Past Projects {#past-projects}

::: {.callout-note icon=false collapse="true"}
## Data-Integrated Training of Surrogate Models for Uncertainty Quantification {#uncertainty-surrogate-models}

![](../images/uncertainty_prop_workflow.png){width=80% fig-alt="Surrogate uncertainty propagation workflow." fig-align="left"}

Uncertainty quantification is crucial to assess the predictive power and limitations
of complex systems models. However, in the case of high-dimensional parameter
spaces and/or complex functional relationships, physics-based simulation models
are often computationally too demanding for rigorous Bayesian uncertainty
quantification. Surrogate models allow for such analyses with much lower effort.
They are typically trained such that they fit the simulation reference best.

What is left unexplored is the possibility of surrogate models to actually fit
observed data better than the reference model. This phenomenon occurs when
structural misspecification of the physics-constrained reference model limits
its performance, but at the same time, the more flexible data-driven surrogate
model can better capture the relation of output and input data. Such situations
offer huge potential for diagnostic evaluation of the modelling approach toward
deeper system understanding and model improvement.

We aim at developing (1) a weighted data-integrated surrogate training approach
for improved predictive performance, (2) a diagnostic approach for structural error
detection in the reference model, and (3) an uncertainty propagation analysis
that accounts for the approximation error introduced by the use of surrogates.

Overarching Topics: 
[Uncertainty Quantification](../research#uncertainty-quantification){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Project Members: [Philipp Reiser](https://de.linkedin.com/in/philipp-reiser-a33163165){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Co-Supervisors: [Anneli Guthke](https://www.simtech.uni-stuttgart.de/exc/people/Guthke/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funders: [Cluster of Excellence SimTech](https://www.simtech.uni-stuttgart.de/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funding Period: 2022 -- 2025

Publications: 

- Scheurer S., **Reiser P.**, Brünnette T., Nowak W., Guthke A., & Bürkner P. C. (in review). Uncertainty-Aware Surrogate-based Amortized Bayesian Inference for Computationally Expensive Models. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2505.08683){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Reiser P.**, Bürkner P. C., & Guthke A. (in review). Bayesian Surrogate Training on Multiple Data Sources: A Hybrid Modeling Strategy. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2412.11875){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/philippreiser/multi-data-source-bayesian-surrogate-paper){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Reiser P.**, Aguilar J. E., Guthke A., & Bürkner P. C. (2025). Uncertainty Quantification and Propagation in Surrogate-based Bayesian Inference. *Statistics and Computing*. doi:10.1007/s11222-025-10597-8
[PDF](../publications/pdf/2025__Reiser_et_al__Statistics_and_Computing.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Journal](https://link.springer.com/article/10.1007/s11222-025-10597-8){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2312.05153){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/philippreiser/bayesian-surrogate-uncertainty-paper){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
:::

<!-- -->

::: {.callout-note icon=false collapse="true"}
## Meta-Uncertainty in Bayesian Model Comparison {#mu-bmb}

![](../images/meta_uncertainty_banner.png){fig-alt="An illustration of meta-uncertainty."}

What we can learn from a single data set in experiments and observational
studies is always limited, and we are inevitably left with some remaining
uncertainty. It is of utmost importance to take this uncertainty into account
when drawing conclusions if we want to make real scientific progress.
Formalizing and quantifying uncertainty is thus at the heart of statistical
methods aiming to obtain insights from data.

To compare scientific theories, scientists translate them into statistical
models and then investigate how well the models' predictions match the gathered
real-world data. One widely applied approach to compare statistical models is
Bayesian model comparison (BMC). Relying on BMC, researchers obtain the
probability that each of the competing models is true (or is closest to the
truth) given the data. These probabilities are measures of uncertainty and, yet,
are also uncertain themselves. This is what we call meta-uncertainty
(uncertainty over uncertainties). Meta-uncertainty affects the conclusions we
can draw from model comparisons and, consequently, the conclusions we can draw
about the underlying scientific theories.

This project contributes to this endeavor by developing and evaluating methods
for quantifying meta-uncertainty in BMC. Building upon mathematical theory of
meta-uncertainty, we will utilize extensive model simulations as an additional
source of information, which enable us to quantify so-far implicit yet important
assumptions of BMC. What is more, we will be able to differentiate between a
closed world, where the true model is assumed to be within the set of considered
models, and an open world, where the true model may not be within that set – a
critical distinction in the context of model comparison procedures.

Overarching Topics: 
[Model Comparison](../research#model-comparison){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Uncertainty Quantification](../research#uncertainty-quantification){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Amortized Inference](../research#abi){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Project Members: [Marvin Schmitt](https://marvin-schmitt.com//){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funders: [Cyber Valley Research Fund](https://cyber-valley.de/en/research-fund){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funding Period: 2021 -- 2025

Publications: 

- **Schmitt M.**, Hikida Y., Radev S. T., Sadlo F., & Bürkner P. C. (in review). The Simplex Projection: Lossless Visualization of 4D Compositional Data on a 2D Canvas. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2403.11141){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Software](https://github.com/marvinschmitt/ggsimplex){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Tutorial](https://marvin-schmitt.com//blog/ggsimplex-prerelease/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- Habermann D., **Schmitt M.**, Kühmichel L., Bulling A., Radev S. T., & Bürkner P. C. (in review). Amortized Bayesian Multilevel Models. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2408.13230){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- Mishra A., Habermann D., **Schmitt M.**, Radev S. T., & Bürkner P. C. (in review). Robust Amortized Bayesian Inference with Self-Consistency Losses on Unlabeled Data. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2501.13483){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Schmitt M.**, Bürkner P. C., Köthe U., & Radev S. T. (accepted). Detecting Model Misspecification in Amortized Bayesian Inference with Neural Networks: An Extended Investigation. *International Journal of Computer Vision*.
[Preprint](https://arxiv.org/abs/2406.03154){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/marvinschmitt/ModelMisspecificationBF){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Schmitt M.**, Pratz V., Köthe U., Bürkner P. C., & Radev S. T. (2024). Consistency Models for Scalable and Fast Simulation-Based Inference. *Proceedings of the Conference on Neural Information Processing Systems (NeurIPS)*.
[PDF](../publications/pdf/2024__Schmitt_et_al__NeurIPS.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Journal](https://proceedings.neurips.cc/paper_files/paper/2024/hash/e58026e2b2929108e1bd24cbfa1c8e4b-Abstract-Conference.html){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2312.05440){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Schmitt M.**, Li C., Vehtari A., Acerbi L., Bürkner P. C., Radev S. T. (2024). Amortized Bayesian Workflow (Extended Abstract). *NeurIPS Workshop on Bayesian Decision-Making and Uncertainty*.
[PDF](../publications/pdf/2024__Schmitt_et_al__NeurIPS_BDU_workshop.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2409.04332){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Schmitt M.**, Ivanova D. R., Habermann D., Köthe U., Bürkner P. C., & Radev S. T. (2024). Leveraging Self-Consistency for Data-Efficient Amortized
Bayesian Inference. *Proceedings of the International Conference on Machine Learning (ICML)*.
[PDF](../publications/pdf/2024__Schmitt_et_al__ICML.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Conference](https://openreview.net/forum?id=uoUOz427RD){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2310.04395){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- Elsemüller L., Olischläger H., **Schmitt M.**, Bürkner P. C., Köthe U., & Radev S. T. (2024). Sensitivity-Aware Amortized Bayesian Inference. *Transactions in Machine Learning Research*.
[PDF](../publications/pdf/2024__Elsemueller_et_al__TMLR.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Journal](https://openreview.net/forum?id=Kxtpa9rvM0){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2310.11122){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/bayesflow-org/SA-ABI){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Schmitt M.**, Radev S. T., & Bürkner P. C. (2024). Fuse It or Lose It: Deep Fusion for Multimodal Simulation-Based Inference. *ArXiv preprint*. doi:10.48550/arXiv.2311.10671
[PDF](../publications/pdf/2024__Schmitt_et_al__arXiv.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2311.10671){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Schmitt M.**, Radev, S. T., & Bürkner P. C. (2023). Meta-Uncertainty in Bayesian Model Comparison. *Artificial Intelligence and Statistics (AISTATS) Conference Proceedings*.
[PDF](../publications/pdf/2023__Schmitt_et_al__AISTATS.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Conference](https://proceedings.mlr.press/v206/schmitt23a.html){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](http://arxiv.org/abs/2210.07278){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/marvinschmitt/MetaUncertaintyPaper){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Talk](../talks/pdf/poster_meta_uncertainty.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Schmitt M.**, Bürkner P. C., Köthe U., & Radev S. T. (2023). Detecting Model Misspecification in Amortized Bayesian Inference with Neural Networks. *Proceedings of the German Conference on Pattern Recognition (GCPR)*. doi:10.1007/978-3-031-54605-1_35
[PDF](../publications/pdf/2023__Schmitt_et_al__GCPR.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Conference](https://link.springer.com/chapter/10.1007/978-3-031-54605-1_35){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2112.08866){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/marvinschmitt/ModelMisspecificationBF){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Talk](../talks/pdf/detecting_MMS_bayesflow.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Poster](../talks/pdf/poster_detecting_MMS_bayesflow.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- Radev S. T., **Schmitt M.**, Pratz V., Picchini U., Köthe U., & Bürkner P. C. (2023). JANA: Jointly Amortized Neural Approximation of Complex Bayesian Models. *Uncertainty in Artificial Intelligence (UAI) Conference Proceedings*.
[PDF](../publications/pdf/2023__Radev_et_al__UAI.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Conference](https://proceedings.mlr.press/v216/radev23a.html){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2302.09125){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/bayesflow-org/JANA-Paper){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Talk](../talks/pdf/glimpse_amortized_bayesian_inference.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- Radev S. T., **Schmitt M.**, Schumacher L., Elsemüller L., Pratz V., Schälte Y., Köthe U., & Bürkner P. C. (2023). BayesFlow: Amortized Bayesian Workflows With Neural Networks. *Journal of Open Source Software*. doi:10.21105/joss.05702
[PDF](../publications/pdf/2023__Radev_et_al__JOSS.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Journal](https://joss.theoj.org/papers/10.21105/joss.05702){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2306.16015){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Software](../software#bayesflow){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Software:

- ggsimplex: Simplex visualizations with ggplot2 [GitHub](https://github.com/marvinschmitt/ggsimplex){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
:::

<!-- -->

::: {.callout-note icon=false collapse="true"}
## Machine Learning for Bayesian Model Building {#ml4bmb}

![](../images/pad-model-taxonomy.png){width=80% fig-alt="An illustration of the PAD model taxonomy." fig-align="left"}

The Bayesian approach to data analysis provides a consistent and flexible way to
handle uncertainty in all observations, model parameters, and model structure
using probability theory. However, building Bayesian models in a principled way
remains a highly complex task requiring a lot of expertise and cognitive
resources. In this project, we will develop a machine assisted workflow for
building interpretable, robust, and well-predicting Bayesian models. Based on
statistical theory, we will develop a framework for simulating realistic data
with known modeling challenges. Subsequently, using neural network architectures
tuned to the structure of the fitted Bayesian models, machines will be trained
on the simulated data to provide automatic model evaluation and modeling
recommendations that guide the user through the model building process using
interactive visualizations. While leaving the modeling choices up to the user,
the machine learns from the user's decisions to improve its recommendations on
the fly.

Overarching Topics: 
[Machine-Assisted Workflows](../research#machine-workflow){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Model Comparison](../research#model-comparison){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Uncertainty Quantification](../research#uncertainty-quantification){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Project Members: [Maximilian Scholz](https://www.scholzmx.com/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funders: [Cluster of Excellence SimTech](https://www.simtech.uni-stuttgart.de/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Funding Period: 2021 -- 2024

Publications:

- Fazio L., **Scholz M.**, Aguilar J. E., & Bürkner P. C. (in review). Primed Priors for Simulation-Based Validation of Bayesian Models. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2408.06504){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://github.com/sims1253/implicit-priors){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Scholz M.** & Bürkner P. C. (in review). Posterior accuracy and calibration under misspecification in Bayesian generalized linear models. *ArXiv preprint*.
[Preprint](https://arxiv.org/abs/2311.09081){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://osf.io/tmdcf/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Software](https://github.com/sims1253/bayesim){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- **Scholz M.** & Bürkner P. C. (2025). Prediction can be safely used as a proxy for explanation in causally consistent Bayesian generalized linear models. *Journal of Statistical Computation and Simulation*. doi:10.1080/00949655.2024.2449534
[PDF](../publications/pdf/2025__Scholz_Buerkner__Journal_of_Statistical_Computation_and_Simulation.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Journal](https://www.tandfonline.com/doi/full/10.1080/00949655.2024.2449534){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](https://arxiv.org/abs/2210.06927){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Code & Data](https://osf.io/xgkzv/){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Software](https://github.com/sims1253/bayesim){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

- Bürkner P. C., **Scholz M.**, & Radev S. T. (2023). Some models are useful, but how do we know which ones? Towards a unified Bayesian model taxonomy. *Statistics Surveys*.
doi:10.1214/23-SS145
[PDF](../publications/pdf/2023__Bürkner_et_al__Statistics_Surveys.pdf){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Journal](https://doi.org/10.1214/23-SS145){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
[Preprint](http://arxiv.org/abs/2209.02439){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}

Software:

- bayesim: Simulations for Bayesian models [GitHub](https://github.com/sims1253/bayesim){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
- bayeshear: Metrics for evaluating Bayesian models [GitHub](https://github.com/sims1253/bayeshear){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
- bayesfam: Custom families for brms [GitHub](https://github.com/sims1253/bayesfam){.btn .btn-outline-primary .btn role="button" .btn-page-header .btn-xs}
:::
