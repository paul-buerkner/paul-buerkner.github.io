[
  {
    "objectID": "cv/index.html",
    "href": "cv/index.html",
    "title": "Curriculum vitae",
    "section": "",
    "text": "Download current CV"
  },
  {
    "objectID": "people/index.html#principal-investigator",
    "href": "people/index.html#principal-investigator",
    "title": "People",
    "section": "Principal Investigator",
    "text": "Principal Investigator\n\n\n\n \n\n\nPaul Bürkner\n\nBackground: Statistics, Mathematics, and Psychology\nPosition: Full Professor for Computational Statistics\nEmail University Website GitHub Google Scholar Twitter"
  },
  {
    "objectID": "people/index.html#postdocs",
    "href": "people/index.html#postdocs",
    "title": "People",
    "section": "PostDocs",
    "text": "PostDocs\n\n\n\n \n\n\nDaniel Habermann\n\nBackground: Computational Biology\nProject: Amortized Bayesian Inference for Multilevel Models\nEmail Personal Website GitHub\n\n\n\n\n\n\n \n\n\nŠimon Kucharský\n\nBackground: Computational Psychology\nProject: Applications of Amortized Bayesian Inference\nEmail Personal Website GitHub"
  },
  {
    "objectID": "people/index.html#phd-students",
    "href": "people/index.html#phd-students",
    "title": "People",
    "section": "PhD Students",
    "text": "PhD Students\n\n\n\n \n\n\nJavier Aguilar\n\nBackground: Mathematics and Statistics\nProject: Intuitive Joint Priors for Bayesian Multilevel Models\nEmail Personal Website GitHub\n\n\n\n\n\n\n \n\n\nFlorence Bockting\n\nBackground: Cognitive Science and Psychology\nProject: Simulation-Based Prior Distributions for Bayesian Models\nEmail Personal Website GitHub\n\n\n\n\n\n\n \n\n\nLuna Fazio\n\nBackground: Biology and Statistics\nProject: Bayesian Distributional Latent Variable Models\nEmail GitHub\n\n\n\n\n\n\n \n\n\nSvenja Jedhoff\n\nBackground: Data Science\nProject: Real-Time Spatio-Temporal Data Analysis for Monitoring Logistics Networks\nCo-Supervisor: Anne Meyer\nEmail\n\n\n\n\n\n\n \n\n\nLars Kühmichel\n\nBackground: Physics and Computer Science\nProject: BayesFlow: Simulation Intelligence with Deep Learning\nCo-Supervisor: Stefan Radev\nEmail GitHub\n\n\n\n\n\n\n \n\n\nAayush Mishra\n\nBackground: Physics and Data Science\nProject: BayesFlow: Simulation Intelligence with Deep Learning\nEmail Linkedin\n\n\n\n\n\n\n \n\n\nSoham Mukherjee\n\nBackground: Statistics\nProject: Probabilistic Models for Single-Cell RNA Sequencing Data\nCo-Supervisor: Manfred Claassen\nEmail University Website Linkedin\n\n\n\n\n\n\n \n\n\nPhilipp Reiser\n\nBackground: Physics and Computer Science\nProject: Data-Integrated Training of Surrogate Models for Uncertainty Quantification\nCo-Supervisor: Anneli Guthke\nEmail University Website GitHub\n\n\n\n\n\n\n \n\n\nMarvin Schmitt\n\nBackground: Psychology and Computer Science\nProject: Meta-Uncertainty in Bayesian Model Comparison\nEmail Personal Website University Website GitHub\n\n\n\n \n\n\n\n\n\n\nAlumni\n\n\n\n\n\n\nMaximilian Scholz (2021 – 2024): PhD Student in my lab before moving to industry. Personal Website GitHub\nStefan Radev (2021 – 2023): PostDoc in my lab before becoming an assistant professor. University Website GitHub Linkedin"
  },
  {
    "objectID": "people/index.html#alumni",
    "href": "people/index.html#alumni",
    "title": "People",
    "section": "Alumni",
    "text": "Alumni\n\n\n\n\n\n\nAlumni\n\n\n\n\n\n\nMaximilian Scholz (2021 – 2024): PhD Student in my lab before moving to industry. Personal Website GitHub\nStefan Radev (2021 – 2023): PostDoc in my lab before becoming assistant professor. University Website GitHub Linkedin"
  },
  {
    "objectID": "software/brms-book/index.html",
    "href": "software/brms-book/index.html",
    "title": "The brms Book",
    "section": "",
    "text": "This is the website of my brms book project. Currently the book is work in progress. I continue to add new chapters here as they get to a sufficiently complete and readable state. Below you can download the current version:\nThe brms Book: Applied Bayesian Regression Modelling Using R and Stan (Early Draft)"
  },
  {
    "objectID": "software/brms-book/index.html#faq",
    "href": "software/brms-book/index.html#faq",
    "title": "The brms Book",
    "section": "FAQ",
    "text": "FAQ\n\nWhen will be complete book be ready?\n\nI am aiming for the second half of 2025 but it may also take a bit longer.\n\nWill the book be freely available online?\n\nYes, I will publish an online version of the book which will be free for non-commercial use. The book will be available also in print and as an ebook published by Chapman and Hall/CRC.\n\nHow can I cite the current version of the book?\n\nPlease cite it as: Bürkner P. C. (2024). The brms Book: Applied Bayesian Regression Modelling Using R and Stan (Early Draft). URL: https://paulbuerkner.com/software/brms-book\n\nI have some ideas how to further improve the content of the book. How can I give you feedback?\n\nFeedback is very welcome! Just write me an email. In the future, I may also host the book’s content on a public GitHub repo, but I haven’t decided on it yet."
  },
  {
    "objectID": "software/brms-blogposts.html",
    "href": "software/brms-blogposts.html",
    "title": "A list of blog posts about brms",
    "section": "",
    "text": "Since its foundation, several people have blogged about my R package brms, which allows to fit Bayesian multilevel models using Stan. This page is intended to provide links to those resources."
  },
  {
    "objectID": "software/brms-blogposts.html#blogs-and-websites",
    "href": "software/brms-blogposts.html#blogs-and-websites",
    "title": "A list of blog posts about brms",
    "section": "Blogs and Websites",
    "text": "Blogs and Websites\n\nBlog of Solomon Kurz\nBlog of Matti Vuorre\nBlog of Ladislas Nalborczyk\nBlog of Markus Gesmann\nBlog of Jonas Kristoffer Lindelov\nBlog of Kristoffer Magnusson\nBlog of Henrik Singmann\nBlog of Daniel Luedecke\nBlog of Wayne Folta\nStatistical Rethinking with brms by Solomon Kurz\nTutorial about brms by Rens van de Schoot"
  },
  {
    "objectID": "software/brms-blogposts.html#individual-blog-posts",
    "href": "software/brms-blogposts.html#individual-blog-posts",
    "title": "A list of blog posts about brms",
    "section": "Individual Blog Posts",
    "text": "Individual Blog Posts\n\nThe evolution of plasticity by Andrew MacDonald\nWhat Explains Union Density? by Steven Miller\nExtracting and visualizing tidy draws from brms models by Matthew Kay\nFitting GAMs with brms: part 1 a simple GAM by Gavin Simpson\nMixed effects models: Is it time to go Bayesian by default? by Michael Frank\nMRP Using brms and tidybayes by Tim Mastny\nBayesian SEM with brms by Jarrett Byrnes\nBayesian Decision Theory Made Ridiculously Simple by Justin Silverman\nR packages interfacing with Stan: brms by Jonah Gabry\nBayesian mixed effects ordinal regression models with brms by Kevin Stadler"
  },
  {
    "objectID": "talks/index.html",
    "href": "talks/index.html",
    "title": "Scientific Talks and Posters",
    "section": "",
    "text": "Below you can find a list of selected talks and posters of me and my group, along with slides, paper references, and recordings when available. Presenters are highlighted in bold.\n\nSchmitt M., Ivanova D. R., Habermann D., Köthe U., Bürkner P. C., & Radev S. T. (2024). Poster: Leveraging Self-Consistency for Data-Efficient Amortized Bayesian Inference. Presented at ICML. Poster Paper\nFazio L., Scholz M., & Bürkner P. C. (2024). Contributed talk: Generative Bayesian Modeling with Implicit Priors. Presented at StanCon. Slides Paper\nBürkner P. C. (2024). Invited talk: A Statistical Perspective on Simulation-Based Inference. Presented at PHYSTAT-SBI. Slides Software\nBockting F., Radev S. T., & Bürkner P. C. (2024). Contributed talk: Normalizing Flows for Simulation Based Expert Prior Elicitation. Presented at MathPsych. Slides\nBockting F., Radev S. T., & Bürkner P. C. (2024). Contributed talk: Simulation-Based Prior Knowledge Elicitation for Parametric Bayesian Models. Presented at ISBA Conference. Slides Paper\nBockting F., Radev S. T., & Bürkner P. C. (2024). Invited talk: Simulation-Based Prior Knowledge Elicitation for Parametric Bayesian Models. Presented at Bayes@Lund. Slides Youtube Paper\nBürkner P. C. (2024). Keynote: Does Bayes have to be slow? A glimpse into amortized Bayesian inference. Presented at Bayes on the Beach. Slides Paper Software\nSchmitt M. & Bürkner P. C. (2024). Workshop: Amortized Bayesian Inference with BayesFlow. Presented at Bayes on the Beach. Notebook Software\nBürkner P. C. (2023). Keynote: Bayesian Probabilistic Modeling for Ecology. Presented at Oxford University. Slides\nBürkner P. C. (2023). Invited talk: Testing evidence of absence with Bayesian methods. Presented at University of Tübingen. Slides\nBürkner P. C. (2023). Invited talk: Best Practices for Supervision of Bachelor’s and Master’s Students. Presented at the International Max Planck Research School for Intelligent Systems. Slides\nAguilar J. E. & Bürkner P. C. (2023). Poster: Intuitive Joint Priors for Bayesian Multilevel Models: The R2D2M2 Prior. Presented at BayesComp. Slides Paper\nSchmitt, M., Radev, S. T., & Bürkner, P. C. (2023). Poster: Meta-Uncertainty in Bayesian Model Comparison. Presented at AISTATS. Slides Paper\nSchmitt, M., Bürkner, P. C., Köthe, U., & Radev, S. T. (2023). Talk: Detecting Model Misspecification in Amortized Bayesian Inference with Neural Networks. Presented at the German Conference on Pattern Recognition. Slides Poster Paper\nSchmitt, M., Habermann, D., Bürkner, P. C., & Radev, S. T. (2023). Talk: Leveraging Self-Consistency for Data-Efficient Amortized Bayesian Inference. Presented at the NeurIPS Workshop for Unifying Representations in Neural Models. Slides Paper\nScholz M. & Bürkner P.C. (2023). Talk: Prediction can be safely used as a proxy for explanation in causally consistent Bayesian GLMs. Presented at Nordstat. Slides Paper\nBürkner P. C., Kröker I., Oladyshkin S., & Nowak W. (2022). Talk: The Sparse Bayesian Polynomial Chaos Expansion. Presented at the DagStat Conference. Slides Paper\nAguilar J. E. & Bürkner P. C. (2022). Talk: Intuitive Joint Priors for Bayesian Multilevel Models Presented at the International Conference on Statistics and Data Science. Slides Paper\nBürkner P. C. (2022). Invited talk: Probabilistic Learning Theory. Presented at the Stuttgart ELLIS unit. Slides Youtube\nBürkner P. C. (2022). Invited talk: Measuring Personality in High-Stakes Situations. Presented at the Interchange Forum for Reflecting on Intelligent Systems. Slides Paper\nBürkner P. C. (2021). Keynote: Bayesian Item Response Modeling in R with brms and Stan. Presented at the Psychoco Conference. Slides Youtube Paper\nBürkner P. C. (2021). Invited talk: Specifying Priors in a Bayesian Workflow. Presented at the Berlin Bayesian Meetup. Slides Youtube\nBürkner P. C. (2021). Keynote: An introduction to Bayesian multilevel modeling with brms. Presented at the Multilevel Conference. Slides Youtube Paper\nBürkner P. C. (2021). Invited talk: Bayesian distributional regression models for cognitive science. Presented at TU Darmstadt University. Slides\nBürkner P. C. (2021). Invited talk: Introduction to Bayesian Statistics. Presented at the Cluster of Excellence SimTech. Slides\nBürkner P. C. (2021). Invited talk: The Past, Present & Future of brms. Presented on learnbayesstats.com. Potcast Youtube Software\nBürkner P. C. (2020). Keynote: A Bayesian Workflow for Data Analysis. Presented at the Summer School on Statistical Methods for Linguistics and Psychology. Slides Paper\nVehtari A., Gelman A., Simpson D., Carpenter B., Bürkner P. C. (2020). Talk: Improving Convergence Diagnostics for MCMC Sampling Algorithms. Presented at the DGPs Methods Conference. Slides Paper\nBürkner P. C., Gabry J., & Vehtari A. (2019). Talk: Approximate leave-future-out cross-validation for Bayesian time series models. Presented at StanCon. Slides Youtube Paper\nBürkner P. C. & Charpentier E. (2019). Talk: Modeling Monotonic Effects of Ordinal Predictors in Regression Models. Presented at the EAM Conference. Slides Paper\nBürkner P. C. (2019). Invited talk: Bayesian model and variable selection using approximate cross-validation and projective predictions. Presented at Imperial College London. Slides\nBürkner P. C. (2018). Talk: Custom Response Distributions with brms. Presented at StanCon. Slides Youtube Software\nBürkner P. C. (2018). Invited talk: From Classical GLMs to Bayesian MLMs. Presented at Insurance Data Science Conference. Slides\nBürkner P. C. (2018). Invited talk: Bayesian Cognitive Models. Presented at the University of Magdeburg. Slides\nBürkner P. C. (2017). Invited talk: Optimal Design and Bayesian Data Analysis. Presented at the DGPs Methods Conference. Slides\nBürkner P. C. (2015). Talk: Optimal Design of Non-Parametric Two-Sample Tests. Presented at the DGPs Methods Conference. Slides Paper"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Research Projects",
    "section": "",
    "text": "Here you can find an overview of my current research projects. A list of past research projects can be found at the bottom of this page."
  },
  {
    "objectID": "projects/index.html#bayesflow-software",
    "href": "projects/index.html#bayesflow-software",
    "title": "Research Projects",
    "section": "BayesFlow: Simulation Intelligence with Deep Learning",
    "text": "BayesFlow: Simulation Intelligence with Deep Learning\nSimulation intelligence (SI) subsumes an emerging generation of scientific methods which utilize digital simulations for emulating and understanding complex real-world systems and phenomena. Recently, neural networks and deep learning have demonstrated a great potential for accelerating and scaling up SI to previously intractable problems and data sets. However, the availability of user-friendly software is still limited, which hampers the widespread and flexible use of modern SI methods.\nIn this project, we focus on software for amortized Bayesian inference, which is an essential part of SI. The hallmark feature of amortized Bayesian inference is an upfront training phase (e.g., of a neural network), which is then amortized by a nearly instant fully Bayesian inference for an arbitrary number of data sets during test time. Concretely, we aim to advance the BayesFlow research software library into becoming the long-term, gold-standard software for amortized Bayesian inference.\nOverarching Topics: Amortized Inference Machine-Assisted Workflows Uncertainty Quantification\nProject Members: Lars Kühmichel Aayush Mishra\nFunders: German Research Foundation (DFG) TU Dortmund University\nFunding Period: 2024 – 2027\nPublications:\n\nHabermann D., Schmitt M., Kühmichel L., Bulling A., Radev S. T., & Bürkner P. C. (in review). Amortized Bayesian Multilevel Models. ArXiv preprint. Preprint"
  },
  {
    "objectID": "projects/index.html#abi-applications",
    "href": "projects/index.html#abi-applications",
    "title": "Research Projects",
    "section": "Applications of Amortized Bayesian Inference",
    "text": "Applications of Amortized Bayesian Inference\nRecent developments in simulation-based amortized inference have ushered in new possibilities for conducting principled Bayesian analysis. The simulation-based approach unlocks the potential of complex models whose likelihoods or priors are not analytically tractable. Amortized approaches make the required computations relatively fast, thus allowing for the deployment of intricate models in scenarios that were hitherto deemed unfeasible or inconvenient. Nevertheless, the novelty of this approach poses a challenge, as its widespread adoption hinges on the availability of user-friendly documentation and resources that simplify entry into the field, as well as empirical examples that validate the method’s usefulness for the practical researchers.\nIn this project, our emphasis is on applications within cognitive modeling and developmental psychology. We focus on how simulation-based amortized inference can address important challenges within the field, not only during the data analysis phase but also in the planning and execution of studies and experiments. As a by-product we will generate tutorials and educational materials providing gentle introductions into the topic. This project also aims to lay the foundations for integrating simulation-based amortized inference with popular statistical software packages used by practitioners who may not have extensive coding skills, thereby broadening the scope of users benefiting from its advantages.\nOverarching Topics: Amortized Inference Latent Variable Modeling Uncertainty Quantification\nProject Members: Šimon Kucharský\nFunders: TU Dortmund University\nFunding Period: 2024 – 2027"
  },
  {
    "objectID": "projects/index.html#amortized-mlms",
    "href": "projects/index.html#amortized-mlms",
    "title": "Research Projects",
    "section": "Amortized Bayesian Inference for Multilevel Models",
    "text": "Amortized Bayesian Inference for Multilevel Models\n\n\n\n\n\nProbabilistic multilevel models (MLMs) are a central building block in Bayesian data analysis. Despite their widely acknowledged advantages, MLMs remain challenging to estimate and evaluate, especially when the involved likelihoods or priors are analytically intractable. Recent developments in generative deep learning and simulation-based inference have shown promising results in scaling up Bayesian inference through amortization. However, the utility of deep generative models for learning Bayesian MLMs remains largely unexplored.\nIn this project, we propose to develop a general and efficient neural inference framework for estimating and evaluating complex Bayesian MLMs. Our framework will substantially extend previous work on simulation-based Bayesian inference for single-level models. Moreover, it aims to encompass not only the inference phase of a Bayesian workflow but also the model evaluation steps, which usually comprise a computational bottleneck with standard (non-amortized) Bayesian methods. Thus, the proposed project has the potential to greatly enhance model-based inference and understanding of complex processes across the quantitative sciences.\nOverarching Topics: Amortized Inference Latent Variable Modeling Uncertainty Quantification\nProject Members: Daniel Habermann\nFunders: German Research Foundation (DFG)\nFunding Period: 2023 – 2026\nPublications:\n\nHabermann D., Schmitt M., Kühmichel L., Bulling A., Radev S. T., & Bürkner P. C. (in review). Amortized Bayesian Multilevel Models. ArXiv preprint. Preprint\nSchmitt M., Ivanova D. R., Habermann D., Köthe U., Bürkner P. C., & Radev S. T. (2024). Leveraging Self-Consistency for Data-Efficient Amortized Bayesian Inference. Proceedings of the International Conference on Machine Learning (ICML). PDF Conference Preprint"
  },
  {
    "objectID": "projects/index.html#bdlvms",
    "href": "projects/index.html#bdlvms",
    "title": "Research Projects",
    "section": "Bayesian Distributional Latent Variable Models",
    "text": "Bayesian Distributional Latent Variable Models\n\n\n\n\n\nIn psychology and related sciences, a lot of research is concerned with studying latent variables, that is, constructs which are not directly observable. Statistical methods for modeling latent variables based on manifest (observable) indicators are thus crucial to the scientific progress in those fields. Two major interconnected statistical areas dealing with latent variables exist, namely, Item Response Theory (IRT) and Structural Equation Modeling (SEM). Although the two fields are closely connected, the frontiers of IRT and SEM have developed in somewhat different directions.\nA combination of these two major frontiers would enable researchers to tackle a lot of advanced psychological research questions at the intersection of psychometrics, personnel psychology, cognitive psychology, and applied psychology. In order for us to gain better insights into behavioral and cognitive processes, their mathematical approximations should match the processes’ complexity in both overall distributional form and its components that are expressed as complex functions of predicting variables.\nThis project aims to develop a framework for Bayesian distributional latent variable models that combines the principles of IRT and SEM with the flexibility of distributional regression powered by modern Bayesian estimation methods.\nOverarching Topics: Latent Variable Modeling Machine-Assisted Workflows Uncertainty Quantification\nProject Members: Luna Fazio\nFunders: German Research Foundation (DFG) TU Dortmund University\nFunding Period: 2022 – 2025\nPublications:\n\nFazio L., Scholz M., & Bürkner P. C. (in review). Generative Bayesian Modeling with Implicit Priors. ArXiv preprint. Preprint Code & Data\nFazio L. & Bürkner P. C. (in review). Gaussian distributional structural equation models: A framework for modeling latent heteroscedasticity. ArXiv preprint. Preprint Code & Data"
  },
  {
    "objectID": "projects/index.html#sbpriors",
    "href": "projects/index.html#sbpriors",
    "title": "Research Projects",
    "section": "Simulation-Based Prior Distributions for Bayesian Models",
    "text": "Simulation-Based Prior Distributions for Bayesian Models\n\n\n\n\n\nData-driven statistical modeling plays a crucial role in almost all quantitative sciences. Despite continuous increases in the amount of available data, the addition of further information sources, such as expert knowledge, often remains an irreplaceable part of setting up high-fidelity models. Grounded in probability theory, Bayesian statistics provides a principled approach to including expert knowledge in the form of prior distributions, a process called prior elicitation. However, prior elicitation for high-dimensional Bayesian models is infeasible with existing methods due to practical and computational challenges. With the goal of solving these challenges, we propose to develop simulation-based priors for high-dimensional Bayesian models that allow to incorporate prior information elicited on any model-implied quantities. We expect the developed methods to have a major impact on all fields applying probabilistic modeling by making the use of expert knowledge practical, robust, and computationally feasible.\nOverarching Topics: Prior Specification Amortized Inference Uncertainty Quantification\nProject Members: Florence Bockting\nFunders: TU Dortmund University Cluster of Excellence SimTech\nFunding Period: 2022 – 2025\nPublications:\n\nBockting F., Radev S. T., & Bürkner P. C. (2024). Simulation-Based Prior Knowledge Elicitation for Parametric Bayesian Models. Scientific Reports. doi:10.1038/s41598-024-68090-7 PDF Journal Preprint Website Code & Data"
  },
  {
    "objectID": "projects/index.html#scrna-models",
    "href": "projects/index.html#scrna-models",
    "title": "Research Projects",
    "section": "Probabilistic Models for Single-Cell RNA Sequencing Data",
    "text": "Probabilistic Models for Single-Cell RNA Sequencing Data\n\n\n\n\n\nTrajectory and pseudo-time inference methods in single-cell RNA sequencing face challenges from the ambiguity of the static single-cell transcriptome snapshot data. In this project, we aim to tackle this challenge by means of advanced probabilistic methods. Concretely, we aim to reconstruct unobserved cell ordering as latent pseudo-time by analyzing RNA spliced counts and corresponding derivative RNA velocity. Further, we aim to obtain uncertainty estimates of the latent cell ordering using Bayesian inference. To achieve these goals, we will develop advanced latent Gaussian process models with the ability of utilizing derivative information to increase precision in estimating unobserved latent inputs. This model deploys derivative covariance kernel functions and modifications in the hyperparameter specifications, thus increasing capabilities for utilizing derivative information in a multi-output setting. Although the primary motivation lies in applications in single-cell biology, this model has the potential to solve similar research problems dealing with multi-output data and its derivatives from diverse fields of study.\nOverarching Topics: Latent Variable Modeling Uncertainty Quantification\nProject Members: Soham Mukherjee\nCo-Supervisors: Manfred Claassen\nFunders: TU Dortmund University University of Tübingen\nFunding Period: 2022 – 2025\nPublications:\n\nMukherjee S., Claassen M., Bürkner P. C. (in review). DGP-LVM: Derivative Gaussian process latent variable model. ArXiv preprint. Preprint Code & Data"
  },
  {
    "objectID": "projects/index.html#uncertainty-surrogate-models",
    "href": "projects/index.html#uncertainty-surrogate-models",
    "title": "Research Projects",
    "section": "Data-Integrated Training of Surrogate Models for Uncertainty Quantification",
    "text": "Data-Integrated Training of Surrogate Models for Uncertainty Quantification\n\n\n\n\n\nUncertainty quantification is crucial to assess the predictive power and limitations of complex systems models. However, in the case of high-dimensional parameter spaces and/or complex functional relationships, physics-based simulation models are often computationally too demanding for rigorous Bayesian uncertainty quantification. Surrogate models allow for such analyses with much lower effort. They are typically trained such that they fit the simulation reference best.\nWhat is left unexplored is the possibility of surrogate models to actually fit observed data better than the reference model. This phenomenon occurs when structural misspecification of the physics-constrained reference model limits its performance, but at the same time, the more flexible data-driven surrogate model can better capture the relation of output and input data. Such situations offer huge potential for diagnostic evaluation of the modelling approach toward deeper system understanding and model improvement.\nWe aim at developing (1) a weighted data-integrated surrogate training approach for improved predictive performance, (2) a diagnostic approach for structural error detection in the reference model, and (3) an uncertainty propagation analysis that accounts for the approximation error introduced by the use of surrogates.\nOverarching Topics: Uncertainty Quantification\nProject Members: Philipp Reiser\nCo-Supervisors: Anneli Guthke\nFunders: Cluster of Excellence SimTech\nFunding Period: 2022 – 2025\nPublications:\n\nReiser P., Aguilar J. E., Guthke A., & Bürkner P. C. (in review). Uncertainty Quantification and Propagation in Surrogate-based Bayesian Inference. ArXiv preprint. Preprint Code & Data"
  },
  {
    "objectID": "projects/index.html#mu-bmb",
    "href": "projects/index.html#mu-bmb",
    "title": "Research Projects",
    "section": "Meta-Uncertainty in Bayesian Model Comparison",
    "text": "Meta-Uncertainty in Bayesian Model Comparison\n\nWhat we can learn from a single data set in experiments and observational studies is always limited, and we are inevitably left with some remaining uncertainty. It is of utmost importance to take this uncertainty into account when drawing conclusions if we want to make real scientific progress. Formalizing and quantifying uncertainty is thus at the heart of statistical methods aiming to obtain insights from data.\nTo compare scientific theories, scientists translate them into statistical models and then investigate how well the models’ predictions match the gathered real-world data. One widely applied approach to compare statistical models is Bayesian model comparison (BMC). Relying on BMC, researchers obtain the probability that each of the competing models is true (or is closest to the truth) given the data. These probabilities are measures of uncertainty and, yet, are also uncertain themselves. This is what we call meta-uncertainty (uncertainty over uncertainties). Meta-uncertainty affects the conclusions we can draw from model comparisons and, consequently, the conclusions we can draw about the underlying scientific theories.\nThis project contributes to this endeavor by developing and evaluating methods for quantifying meta-uncertainty in BMC. Building upon mathematical theory of meta-uncertainty, we will utilize extensive model simulations as an additional source of information, which enable us to quantify so-far implicit yet important assumptions of BMC. What is more, we will be able to differentiate between a closed world, where the true model is assumed to be within the set of considered models, and an open world, where the true model may not be within that set – a critical distinction in the context of model comparison procedures.\nOverarching Topics: Model Comparison Uncertainty Quantification Amortized Inference\nProject Members: Marvin Schmitt\nFunders: Cyber Valley Research Fund\nFunding Period: 2021 – 2024\nPublications:\n\nSchmitt M., Radev S. T., & Bürkner P. C. (in review). Fuse It or Lose It: Deep Fusion for Multimodal Simulation-Based Inference. ArXiv preprint. Preprint\nSchmitt M., Hikida Y., Radev S. T., Sadlo F., & Bürkner P. C. (in review). The Simplex Projection: Lossless Visualization of 4D Compositional Data on a 2D Canvas. ArXiv preprint. Preprint Software Tutorial\nSchmitt M., Pratz V., Köthe U., Bürkner P. C., & Radev S. T. (accepted). Consistency Models for Scalable and Fast Simulation-Based Inference. Proceedings of the Conference on Neural Information Processing Systems (NeurIPS). Preprint\nSchmitt M., Ivanova D. R., Habermann D., Köthe U., Bürkner P. C., & Radev S. T. (2024). Leveraging Self-Consistency for Data-Efficient Amortized Bayesian Inference. Proceedings of the International Conference on Machine Learning (ICML). PDF Conference Preprint\nElsemüller L., Olischläger H., Schmitt M., Bürkner P. C., Köthe U., & Radev S. T. (2024). Sensitivity-Aware Amortized Bayesian Inference. Transactions in Machine Learning Research. PDF Journal Preprint Code & Data\nSchmitt, M., Radev, S. T., & Bürkner P. C. (2023). Meta-Uncertainty in Bayesian Model Comparison. Artificial Intelligence and Statistics (AISTATS) Conference Proceedings. PDF Conference Preprint Code & Data Talk\nSchmitt, M., Bürkner P. C., Köthe U., & Radev S. T. (2023). Detecting Model Misspecification in Amortized Bayesian Inference with Neural Networks. Proceedings of the German Conference on Pattern Recognition (GCPR). doi:10.1007/978-3-031-54605-1_35 PDF Conference Preprint Code & Data Talk Poster\nRadev S. T., Schmitt M., Pratz V., Picchini U., Köthe U., & Bürkner P. C. (2023). JANA: Jointly Amortized Neural Approximation of Complex Bayesian Models. Uncertainty in Artificial Intelligence (UAI) Conference Proceedings. PDF Conference Preprint Code & Data Talk\nRadev S. T., Schmitt M., Schumacher L., Elsemüller L., Pratz V., Schälte Y., Köthe U., & Bürkner P. C. (2023). BayesFlow: Amortized Bayesian Workflows With Neural Networks. Journal of Open Source Software. doi:10.21105/joss.05702 PDF Journal Preprint Software\n\nSoftware:\n\nggsimplex: Simplex visualizations with ggplot2 GitHub"
  },
  {
    "objectID": "projects/index.html#joint-priors-mlms",
    "href": "projects/index.html#joint-priors-mlms",
    "title": "Research Projects",
    "section": "Intuitive Joint Priors for Bayesian Multilevel Models",
    "text": "Intuitive Joint Priors for Bayesian Multilevel Models\n\nRegression models are ubiquitous in the quantitative sciences making up a big part of all statistical analysis performed on data. In the quantitative sciences, data often contains multilevel structure, for example, because of natural groupings of individuals or repeated measurement of the same individuals. Multilevel models (MLMs) are designed specifically to account for the nested structure in multilevel data and are a widely applied class of regression models. From a Bayesian perspective, the widespread success of MLMs can be explained by the fact that they impose joint priors over a set of parameters with shared hyper-parameters, rather than separate independent priors for each parameter. However, in almost all state-of-the-art approaches, different additive regression terms in MLMs, corresponding to different parameter sets, still receive mutually independent priors. As more and more terms are being added to the model while the number of observations remains constant, such models will overfit the data. This is highly problematic as it leads to unreliable or uninterpretable estimates, bad out-of-sample predictions, and inflated Type I error rates.\nTo solve these challenges, this project aims to develop, evaluate, implement, and apply intuitive joint priors for Bayesian MLMs. We hypothesize that our developed priors will enable the reliable and interpretable estimation of much more complex Bayesian MLMs than was previously possible.\nOverarching Topics: Prior Specification Uncertainty Quantification\nProject Members: Javier Aguilar\nFunders: German Research Foundation (DFG) TU Dortmund University University of Stuttgart\nFunding Period: 2021 – 2025\nPublications:\n\nAguilar J. E. & Bürkner P. C. (in review). Generalized Decomposition Priors on R2. ArXiv preprint. Preprint Code & Data\nReiser P., Aguilar J. E., Guthke A., & Bürkner P. C. (in review). Uncertainty Quantification and Propagation in Surrogate-based Bayesian Inference. ArXiv preprint. Preprint Code & Data\nAguilar J. E. & Bürkner P. C. (2023). Intuitive Joint Priors for Bayesian Linear Multilevel Models: The R2D2M2 prior. Electronic Journal of Statistics. doi:10.1214/23-EJS2136 PDF Journal Preprint Code & Data Talk"
  },
  {
    "objectID": "projects/index.html#ml4bmb",
    "href": "projects/index.html#ml4bmb",
    "title": "Research Projects",
    "section": "Machine Learning for Bayesian Model Building",
    "text": "Machine Learning for Bayesian Model Building\n\n\n\n\n\nThe Bayesian approach to data analysis provides a consistent and flexible way to handle uncertainty in all observations, model parameters, and model structure using probability theory. However, building Bayesian models in a principled way remains a highly complex task requiring a lot of expertise and cognitive resources. In this project, we will develop a machine assisted workflow for building interpretable, robust, and well-predicting Bayesian models. Based on statistical theory, we will develop a framework for simulating realistic data with known modeling challenges. Subsequently, using neural network architectures tuned to the structure of the fitted Bayesian models, machines will be trained on the simulated data to provide automatic model evaluation and modeling recommendations that guide the user through the model building process using interactive visualizations. While leaving the modeling choices up to the user, the machine learns from the user’s decisions to improve its recommendations on the fly.\nOverarching Topics: Machine-Assisted Workflows Model Comparison Uncertainty Quantification\nProject Members: Maximilian Scholz\nFunders: Cluster of Excellence SimTech\nFunding Period: 2021 – 2024\nPublications:\n\nFazio L., Scholz M., & Bürkner P. C. (in review). Generative Bayesian Modeling with Implicit Priors. ArXiv preprint. Preprint Code & Data\nScholz M. & Bürkner P. C. (in review). Prediction can be safely used as a proxy for explanation in causally consistent Bayesian generalized linear models. ArXiv preprint. Preprint Code & Data\nScholz M. & Bürkner P. C. (in review). Posterior accuracy and calibration under misspecification in Bayesian generalized linear models. ArXiv preprint. Preprint Code & Data\nBürkner P. C., Scholz M., & Radev S. T. (2023). Some models are useful, but how do we know which ones? Towards a unified Bayesian model taxonomy. Statistics Surveys. doi:10.1214/23-SS145 PDF Journal Preprint\n\nSoftware:\n\nbayesim: Simulations for Bayesian models GitHub\nbayeshear: Metrics for evaluating Bayesian models GitHub\nbayesfam: Custom families for brms GitHub"
  },
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Research",
    "section": "",
    "text": "Probabilistic (Bayesian) approaches to statistics and machine learning have become increasingly popular due to new developments in probabilistic programming languages and associated learning algorithms as well as a steady increase in overall computing power. Probabilistic programming languages make it easier to specify and fit Bayesian models, but this still leaves us with many options regarding constructing, evaluating, and using these models, along with many remaining challenges in computation. My overarching scientific goal is to develop principled Bayesian workflows that comprise the whole scientific process from design of studies, data gathering and cleaning over model building, calibration, fitting and evaluation, to the post-processing and statistical decision making. As such, we are working on a wide range of research topics related to the development, evaluation, implementation, or application of Bayesian methods. Some of my current core research areas are detailed below."
  },
  {
    "objectID": "research/index.html#uncertainty-quantification",
    "href": "research/index.html#uncertainty-quantification",
    "title": "Research",
    "section": "Uncertainty Quantification",
    "text": "Uncertainty Quantification\nIn experiments and observational studies, scientists gather data to learn more about the world. However, what we can learn from a single data set is always limited, and we are inevitably left with some remaining uncertainty. It is of high importance to take this uncertainty into account when drawing conclusions if we want to make real scientific progress. Formalizing and quantifying uncertainty is thus at the heart of statistical methods aiming to obtain insights from data. In my lab, all projects, in one way or the other, deal with uncertainty quantification and propagation, primarily through sampling-based methods."
  },
  {
    "objectID": "research/index.html#prior-specification",
    "href": "research/index.html#prior-specification",
    "title": "Research",
    "section": "Prior Specification",
    "text": "Prior Specification\nSpecification of prior distributions for a Bayesian model is a central part of the Bayesian workflow for data analysis, but it is often difficult even for statistical experts. Prior elicitation transforms domain knowledge of various kinds into well-defined prior distributions, and offers a solution to the prior specification problem, in principle. In practice, however, we are still far from having usable prior elicitation tools that could significantly influence the way we build probabilistic models especially for high-dimensional problems. We are approaching this challenge from two perspectives, (a) by developing intuitive joint prior distributions that yield sensible prior predictions even in high-dimensional spaces and (b) by building prior elicitation tools that transform expert knowledge in the data space into prior distributions on the model parameters that are consistent with that knowledge while satisfying additional probabilistic constraints.\nCurrent projects:\n\nSimulation-Based Prior Distributions\nIntuitive Joint Priors for Bayesian Multilevel Models"
  },
  {
    "objectID": "research/index.html#abi",
    "href": "research/index.html#abi",
    "title": "Research",
    "section": "Amortized Inference",
    "text": "Amortized Inference\nMost Bayesian inference algorithms have to be re-run from scratch for every new dataset or change in prior assumptions, with every run requiring considerable time and computational resources. As a result, Bayesian inference is usually infeasible in situations that require a lot of model re-fits or when results need to be available in real-time. The new field of Amortized Bayesian inference (ABI) offers a path towards solving these challenges. In a nutshell, ABI consists of (1) a training phase where neural networks distill relevant information from any probabilistic model and (2) an inference phase where the networks infer the hidden parameters of the model in real time for any new query. Currently, existing ABI methods only work reliably for relatively simple models and there remain several open challenges regarding the accuracy, scalability, and robustness of these methods; challenges that my lab aims to address in the upcoming years. In the process, we will also bridge the gap between simulation-based and likelihood-based Bayesian inference, thus maximizing the information usable during both training and inference. If you want to learn more about the field of amortized inference, please check out our curated awesome-amortized-inference list of resources and references.\nCurrent projects:\n\nBayesFlow: Simulation Intelligence with Deep Learning\nAmortized Bayesian Inference for Multilevel Models\nApplications of Amortized Bayesian Inference\nSimulation-Based Prior Distributions\nMeta-Uncertainty in Bayesian Model Comparison"
  },
  {
    "objectID": "research/index.html#lvm",
    "href": "research/index.html#lvm",
    "title": "Research",
    "section": "Latent Variable Modeling",
    "text": "Latent Variable Modeling\nLatent variables are not directly observable, yet they often represent a core part of a scientific theory. For example, psychologists model intelligence and personality, biologists study properties of viruses and bacteria, and economists aim to understand the underlying properties of a market. Statistical methods for modeling latent variables based on manifest (observable) indicators are thus crucial to the scientific progress in those fields. When using modern Bayesian inference approaches, latent variables can be represented as parameters, whose posterior distribution can thus be learned directly from data along with all other model parameters. However, Bayesian latent variable models are also highly challenging to estimate. Not only are they computationally demanding, but they also frequently suffer from convergence issues as well as challenges in choosing the right parameterization and appropriate prior distributions. In our research, we are tackling the specification, estimation, and evaluation of Bayesian latent variable models from various different angles, including amortized and non-amortized approaches.\nCurrent projects:\n\nBayesian Distributional Latent Variable Models\nProbabilistic Models for Single-Cell RNA Sequencing Data\nAmortized Bayesian Inference for Multilevel Models\nApplications of Amortized Bayesian Inference"
  },
  {
    "objectID": "research/index.html#model-comparison",
    "href": "research/index.html#model-comparison",
    "title": "Research",
    "section": "Model Comparison",
    "text": "Model Comparison\nNumerous research questions in basic science are concerned with comparing multiple scientific theories to understand which of them is more likely to be true, or at least closer to the truth. To compare these theories, scientists translate them into statistical models and then investigate how well the models’ predictions match the gathered real-world data. Even if the goal is purely predictive, model comparison is very important for predictive model selection or averaging. In my lab, we are exploring Bayesian model comparison approaches from both theory-driven and predictive perspectives and even seek to find ways to combine both perspectives.\nCurrent projects:\n\nMeta-Uncertainty in Bayesian Model Comparison\nMachine Learning for Bayesian Model Building"
  },
  {
    "objectID": "research/index.html#machine-workflow",
    "href": "research/index.html#machine-workflow",
    "title": "Research",
    "section": "Machine-Assisted Workflows",
    "text": "Machine-Assisted Workflows\nBuilding Bayesian models in a principled way remains a highly complex task requiring a lot of expertise and cognitive resources. Ideally, subject matter experts do not have to solve everything by themselves but have statisticians or data scientists by their side to assist them. Of course, the latter are not always available for every data-analysis project. As a remedy we are developing machine-assisted workflows for building interpretable, robust, and well-predicting Bayesian models. This first requires more research on the theoretical foundations of Bayesian model building. With this in hand, machines will be trained to provide automatic model evaluation and modeling recommendations that guide the user through the model building process. While leaving the modeling choices up to the user, the machine subsequently learns from the user’s decisions to improve its recommendations on the fly.\nCurrent projects:\n\nMachine Learning for Bayesian Model Building\nBayesFlow: Simulation Intelligence with Deep Learning\nBayesian Distributional Latent Variable Models"
  },
  {
    "objectID": "publications/index.html",
    "href": "publications/index.html",
    "title": "Scientific Publications",
    "section": "",
    "text": "Aguilar J. E. & Bürkner P. C. (in review). Generalized Decomposition Priors on R2. ArXiv preprint. Preprint Code & Data\nBockting F., Radev S. T., & Bürkner P. C. (in review). Expert-elicitation method for non-parametric joint priors using normalizing flows. ArXiv preprint. Preprint Code Data\nFazio L., Scholz M., & Bürkner P. C. (in review). Generative Bayesian Modeling with Implicit Priors. ArXiv preprint. Preprint Code & Data\nFazio L. & Bürkner P. C. (in review). Gaussian distributional structural equation models: A framework for modeling latent heteroscedasticity. ArXiv preprint. Preprint Code & Data\nHabermann D., Schmitt M., Kühmichel L., Bulling A., Radev S. T., & Bürkner P. C. (in review). Amortized Bayesian Multilevel Models. ArXiv preprint. Preprint\nMukherjee S., Claassen M., Bürkner P. C. (in review). DGP-LVM: Derivative Gaussian process latent variable models. ArXiv preprint. Preprint Code & Data\nReiser P., Aguilar J. E., Guthke A., & Bürkner P. C. (in review). Uncertainty Quantification and Propagation in Surrogate-based Bayesian Inference. ArXiv preprint. Preprint Code & Data\nSchmitt M., Radev S. T., & Bürkner P. C. (in review). Fuse It or Lose It: Deep Fusion for Multimodal Simulation-Based Inference. ArXiv preprint. Preprint\nSchmitt M., Hikida Y., Radev S. T., Sadlo F., & Bürkner P. C. (in review). The Simplex Projection: Lossless Visualization of 4D Compositional Data on a 2D Canvas. ArXiv preprint. Preprint Software Tutorial\nSchmitt, M., Bürkner P. C., Köthe U., & Radev S. T. (2023). Detecting Model Misspecification in Amortized Bayesian Inference with Neural Networks: An Extended Investigation. ArXiv preprint. Preprint Code & Data\nScholz M. & Bürkner P. C. (in review). Posterior accuracy and calibration under misspecification in Bayesian generalized linear models. ArXiv preprint. Preprint Code & Data Software\nMagnusson M., Torgander J., Bürkner P. C., Zhang L., Carpenter B., & Vehtari A. (in review). posteriordb: Testing, Benchmarking and Developing Bayesian Inference Algorithms. ArXiv preprint. Preprint Software\nKołczyńska M., & Bürkner P. C. (in review). Does political trust strengthen democracy? SocArXiv preprint. Preprint Code & Data\nRevathe T., Mundry R., Utami-Atmoko S. S., Aprilla T. U., van Noordwijk M. A., Fröhlich M., Bürkner P. C., Schuppli C. (in review). Sumatran orangutan mothers differ in the extent and trajectory of their expression of maternal behaviour. bioXiv preprint. Preprint"
  },
  {
    "objectID": "publications/index.html#in-review",
    "href": "publications/index.html#in-review",
    "title": "Scientific Publications",
    "section": "",
    "text": "Aguilar J. E. & Bürkner P. C. (in review). Generalized Decomposition Priors on R2. ArXiv preprint. Preprint Code & Data\nBockting F., Radev S. T., & Bürkner P. C. (in review). Expert-elicitation method for non-parametric joint priors using normalizing flows. ArXiv preprint. Preprint Code Data\nFazio L., Scholz M., & Bürkner P. C. (in review). Generative Bayesian Modeling with Implicit Priors. ArXiv preprint. Preprint Code & Data\nFazio L. & Bürkner P. C. (in review). Gaussian distributional structural equation models: A framework for modeling latent heteroscedasticity. ArXiv preprint. Preprint Code & Data\nHabermann D., Schmitt M., Kühmichel L., Bulling A., Radev S. T., & Bürkner P. C. (in review). Amortized Bayesian Multilevel Models. ArXiv preprint. Preprint\nMukherjee S., Claassen M., Bürkner P. C. (in review). DGP-LVM: Derivative Gaussian process latent variable models. ArXiv preprint. Preprint Code & Data\nReiser P., Aguilar J. E., Guthke A., & Bürkner P. C. (in review). Uncertainty Quantification and Propagation in Surrogate-based Bayesian Inference. ArXiv preprint. Preprint Code & Data\nSchmitt M., Radev S. T., & Bürkner P. C. (in review). Fuse It or Lose It: Deep Fusion for Multimodal Simulation-Based Inference. ArXiv preprint. Preprint\nSchmitt M., Hikida Y., Radev S. T., Sadlo F., & Bürkner P. C. (in review). The Simplex Projection: Lossless Visualization of 4D Compositional Data on a 2D Canvas. ArXiv preprint. Preprint Software Tutorial\nSchmitt, M., Bürkner P. C., Köthe U., & Radev S. T. (2023). Detecting Model Misspecification in Amortized Bayesian Inference with Neural Networks: An Extended Investigation. ArXiv preprint. Preprint Code & Data\nScholz M. & Bürkner P. C. (in review). Posterior accuracy and calibration under misspecification in Bayesian generalized linear models. ArXiv preprint. Preprint Code & Data Software\nMagnusson M., Torgander J., Bürkner P. C., Zhang L., Carpenter B., & Vehtari A. (in review). posteriordb: Testing, Benchmarking and Developing Bayesian Inference Algorithms. ArXiv preprint. Preprint Software\nKołczyńska M., & Bürkner P. C. (in review). Does political trust strengthen democracy? SocArXiv preprint. Preprint Code & Data\nRevathe T., Mundry R., Utami-Atmoko S. S., Aprilla T. U., van Noordwijk M. A., Fröhlich M., Bürkner P. C., Schuppli C. (in review). Sumatran orangutan mothers differ in the extent and trajectory of their expression of maternal behaviour. bioXiv preprint. Preprint"
  },
  {
    "objectID": "publications/index.html#accepted",
    "href": "publications/index.html#accepted",
    "title": "Scientific Publications",
    "section": "Accepted",
    "text": "Accepted\n\nSchmitt M., Pratz V., Köthe U., Bürkner P. C., & Radev S. T. (accepted). Consistency Models for Scalable and Fast Simulation-Based Inference. Proceedings of the Conference on Neural Information Processing Systems (NeurIPS). Preprint\nScholz M. & Bürkner P. C. (accepted). Prediction can be safely used as a proxy for explanation in causally consistent Bayesian generalized linear models. Journal of Statistical Computation and Simulation. Preprint Code & Data Software\nShi L., Bürkner P. C., & Bulling A. (accepted). ActionDiffusion: An Action-aware Diffusion Model for Procedure Planning in Instructional Videos. IEEE/CVF Winter Conference on Applications of Computer Vision (WACV). Preprint\nDubova, M., Chandramouli, S., Gigerenzer, G., …, Wagenmarkers E. J., Bürkner P. C., & Sloman, S. (accepted). Is Occam’s razor losing its edge? New perspectives on the principle of model parsimony. Proceedings of the National Academy of Sciences (PNAS). Preprint\nIngram D. J., Froese G. Z. L., Carroll D., Bürkner P. C., …, Abernethy K., & Coad L. (accepted). Regional patterns of wild animal hunting in African tropical forests. Nature Sustainability.\nBagaïni A., Liu Y., Kapoor M., Son G., Bürkner P. C., Tisdall L., & Mata R. (accepted). Comparing the Temporal Stability and Convergent Validity of Risk Preference Measures: A Meta-Analytic Approach. Nature Human Behavior. Preprint Code & Data\nLingel H., Bürkner P. C., Melchers K. G., & Schulte N. (accepted). Measuring Personality When Stakes Are High: Are Graded Paired Comparisons a More Reliable Alternative to Traditional Forced-Choice Methods? Organizational Research Methods. Preprint Code & Data Data"
  },
  {
    "objectID": "publications/index.html#section",
    "href": "publications/index.html#section",
    "title": "Scientific Publications",
    "section": "2024",
    "text": "2024\n\nBockting F., Radev S. T., & Bürkner P. C. (2024). Simulation-Based Prior Knowledge Elicitation for Parametric Bayesian Models. Scientific Reports. doi:10.1038/s41598-024-68090-7 PDF Journal Preprint Code & Data\nSchmitt M., Ivanova D. R., Habermann D., Köthe U., Bürkner P. C., & Radev S. T. (2024). Leveraging Self-Consistency for Data-Efficient Amortized Bayesian Inference. Proceedings of the International Conference on Machine Learning (ICML). PDF Conference Preprint\nKallioinen N., Paananen T., Bürkner P. C., & Vehtari A. (2024). Detecting and diagnosing prior and likelihood sensitivity with power-scaling. Statistics and Computing. doi:10.1007/s11222-023-10366-5 PDF Journal Preprint Code & Data Software\nElsemüller L., Olischläger H., Schmitt M., Bürkner P. C., Köthe U., & Radev S. T. (2024). Sensitivity-Aware Amortized Bayesian Inference. Transactions in Machine Learning Research. PDF Journal Preprint Code & Data\nElsemüller L., Schnuerch M., Bürkner P. C., & Radev S. T. (2024). A Deep Learning Method for Comparing Bayesian Hierarchical Models. Psychological Methods. doi:10.1037/met0000645 PDF Journal Preprint Code & Data\nHuber F., Bürkner P. C., Göddeke D., & Schulte M. (2024). Knowledge-based modeling of simulation behavior for Bayesian optimization. Computational Mechanics. doi:10.1007/s00466-023-02427-3 PDF Journal Code & Data\nSchmitt M., Li C., Vehtari A., Acerbi L., Bürkner P. C., Radev S. T. (2024). Amortized Bayesian Workflow (Extended Abstract). NeurIPS Workshop on Bayesian Decision-Making and Uncertainty. PDF Preprint\nRaulo A., Bürkner P. C., Dale J., English H., Finerty G., Lamberth C., Firth J. A., Coulson T., & Knowles S. (2024). Social and environmental transmission spread different sets of gut microbes in wild mice. Nature Ecology & Evolution. doi:10.1038/s41559-024-02381-0 PDF Journal Preprint Code Data\nKołczyńska M., Bürkner P. C., Kennedy L., & Vehtari A. (2024). Trust in state institutions in Europe, 1989-2019. Survey Research Methods. doi:10.18148/srm/2024.v18i1.8119 PDF Journal Preprint Code & Data\nRevathe T., Mundry R., Atmoko S. S. U., Bürkner P. C., van Noordwijk M. A., & Schuppli C. (2024). Maternal behavior in Sumatran orangutans (Pongo abelii) is modulated by mother-offspring characteristics and socioecological factors. International Journal of Primatology. doi:10.1007/s10764-024-00435-5 PDF Journal Preprint Code & Data\nSchmitt M., Ewendt F., Kluttig A., Mikolajczyk R., Kraus B., Waetjen W., Bürkner P. C., Stangl G., & Föller M. (2024). Smoking is associated with increased eryptosis, suicidal erythrocyte death, in a large population-based cohort. Scientific Reports. doi:10.1038/s41598-024-53258-y PDF Journal\nGarcia-Argibay M., Bürkner P. C., Lichtenstein P., Zhang L., D’Onofrio B. M., Andell P., Chang Z., Cortese S., & Larsson H. (2024). Methylphenidate and Short-Term Cardiovascular Risk. JAMA Network Open. doi:10.1001/jamanetworkopen.2024.1349 PDF Journal\nSchulte N., Kaup L., Bürkner P. C., & Holling H. (2024). The Fakeability of Personality Measurement with Graded Paired Comparisons. Journal of Business and Psychology. doi:10.1007/s10869-024-09931-0 PDF Journal Preprint Preregistration Code & Data\nZetsche U., Neumann P., Bürkner P. C., Renneberg B., Koster E. H. W., & Hoorelbeke K. (2024). Computerized Cognitive Training to Reduce Rumination in Major Depression: A Randomized Controlled Trial. Behaviour Research and Therapy. doi:10.1016/j.brat.2024.104521 PDF Journal Preprint Preregistration Code & Data\nBolzenkötter T., Bürkner P. C., Zetsche U., & Schulze L. (2024). Assessing the Immediate Effects of Detached Mindfulness on Repetitive Negative Thinking and Affect in Daily Life: A Randomized Controlled Trial. Mindfulness. doi:10.1007/s12671-024-02350-5 PDF Journal Preprint Code & Data\nWhitridge J. W., Huff M. J., Ozubko J. D., Bürkner P. C., Lahey C. D., & Fawcett J. M. (2024). Singing does not necessarily improve memory more than reading aloud: An empirical and meta-analytic investigation. Experimental Psychology. doi:10.1027/1618-3169/a000614 PDF Journal Code & Data"
  },
  {
    "objectID": "publications/index.html#section-1",
    "href": "publications/index.html#section-1",
    "title": "Scientific Publications",
    "section": "2023",
    "text": "2023\n\nBürkner P. C., Scholz M., & Radev S. T. (2023). Some models are useful, but how do we know which ones? Towards a unified Bayesian model taxonomy. Statistics Surveys. doi:10.1214/23-SS145 PDF Journal Preprint\nBürkner P. C., Kröker I., Oladyshkin S., & Nowak W. (2023). A fully Bayesian sparse polynomial chaos expansion approach with joint priors on the coefficients and global selection of terms. Journal of Computational Physics. doi:10.1016/j.jcp.2023.112210 PDF Journal Preprint Code & Data Talk\nRadev S. T., Schmitt M., Pratz V., Picchini U., Köthe U., & Bürkner P. C. (2023). JANA: Jointly Amortized Neural Approximation of Complex Bayesian Models. Uncertainty in Artificial Intelligence (UAI) Conference Proceedings. PDF Conference Preprint Code & Data Talk\nAguilar J. E. & Bürkner P. C. (2023). Intuitive Joint Priors for Bayesian Linear Multilevel Models: The R2D2M2 prior. Electronic Journal of Statistics. doi:10.1214/23-EJS2136 PDF Journal Preprint Code & Data Talk\nSchmitt, M., Radev, S. T., & Bürkner P. C. (2023). Meta-Uncertainty in Bayesian Model Comparison. Artificial Intelligence and Statistics (AISTATS) Conference Proceedings. PDF Conference Preprint Code & Data Talk\nSchmitt, M., Bürkner P. C., Köthe U., & Radev S. T. (2023). Detecting Model Misspecification in Amortized Bayesian Inference with Neural Networks. Proceedings of the German Conference on Pattern Recognition (GCPR). doi:10.1007/978-3-031-54605-1_35 PDF Conference Preprint Code & Data Talk Poster\nSchumacher L., Bürkner P. C., Voss A., Köthe U., & Radev S. T. (2023). Neural Superstatistics: A Bayesian Method for Estimating Dynamic Models of Cognition. Scientific Reports. doi:10.1038/s41598-023-40278-3 PDF Journal Preprint Code & Data\nModrák M., Moon A. H., Kim S., Bürkner P. C., Huurre N., Faltejsková K., Gelman A., & Vehtari A. (2023). Simulation-Based Calibration Checking for Bayesian Computation: The Choice of Test Quantities Shapes Sensitivity. Bayesian Analysis. doi:10.1214/23-BA1404 PDF Journal Preprint Code & Data\nPerini L., Bürkner P. C., & Klami A. (2023). Estimating the Contamination Factor’s Distribution in Unsupervised Anomaly Detection. Proceedings of the International Conference on Machine Learning (ICML). PDF Conference Preprint Code & Data\nRiutort-Mayol G., Bürkner P. C., Andersen M. R., Solin A., & Vehtari A. (2023). Practical Hilbert space approximate Bayesian Gaussian processes for probabilistic programming. Statistics and Computing. doi:10.1007/s11222-022-10167-2 PDF Journal Preprint Code & Data\nMikkola P., Martin O., Chandramouli S., …, Bürkner P. C., & Klami A. (2023). Prior knowledge elicitation: The past, present, and future. Bayesian Analysis. doi:10.1214/23-BA1381 PDF Journal Preprint\nRadev S. T., Schmitt M., Schumacher L., Elsemüller L., Pratz V., Schälte Y., Köthe U., & Bürkner P. C. (2023). BayesFlow: Amortized Bayesian Workflows With Neural Networks. Journal of Open Source Software. doi:10.21105/joss.05702 PDF Journal Preprint Software\nRodriguez, J. E., Williams, D. R., & Bürkner P. C. (2023). Heterogeneous Heterogeneity by Default: Testing Categorical Moderators in Random-effects Meta-Analysis. British Journal of Mathematical and Statistical Psychology. doi:10.1111/bmsp.12299 PDF Journal Preprint Code & Data\nKołczyńska M. & Bürkner P. C. (2023). Modeling public opinion over time: A simulation study of latent trend models. Journal of Survey Statistics and Methodology. doi:10.1093/jssam/smad024 PDF Journal Preprint Code & Data\nShi L., Bürkner P. C., & Bulling A. (2023). Inferring Human Intentions from Predicted Action Probabilities. ArXiv preprint. doi:10.48550/arXiv.2308.12194 PDF Preprint\nArslan, R. C., Blake, K., Botzet, L., Bürkner, P. C., DeBruine, L. M., Fiers, T., …, & Stern, J. (2023). Not within spitting distance: salivary immunoassays of estradiol have subpar validity for cycle phase. Psychoneuroendocrinology. doi:10.1016/j.psyneuen.2022.105994 PDF Journal Preprint Code & Data\nZetsche, U., Bürkner P. C., Bohländer, J., Renneberg, B., Röpke, S., & Schulze, L. (2023). Daily Emotion Regulation in Major Depression and Borderline Personality Disorder. Clinical Psychological Science. doi:10.1177/21677026231160709 PDF Journal Preprint Code & Data\nDanböck, S. K., Franke, L. K., Miedl, S. F., Liedlgruber, M., Bürkner P. C., & Wilhelm, F. H. (2023). Experimental Manipulations and Multi-Domain Measures of Negative Affect and Pain Are Linked to Peritraumatic Dissociation. Behaviour Research and Therapy. doi:10.1016/j.brat.2023.104289 PDF Journal Preprint Code & Data\nZhang, J., Bürkner P. C., Kiesel A., & Dignath D. (2023). How Emotional Stimuli Modulate Cognitive Control: A Meta-Analytic Review of Studies With Conflict Tasks. Psychological Bulletin. doi:10.1037/bul0000389 PDF Journal Code & Data\nEwendt, F., Schmitt, M., Kluttig, A., Kühn, J., …, Bürkner P. C., Föller, M., & Stangl, G. I. (2023). Association between vitamin D status and eryptosis – results from the German National Cohort Study. Annals of Hematology. doi:10.1007/s00277-023-05239-w PDF Journal"
  },
  {
    "objectID": "publications/index.html#section-2",
    "href": "publications/index.html#section-2",
    "title": "Scientific Publications",
    "section": "2022",
    "text": "2022\n\nBürkner P. C. (2022). On the information obtainable from comparative judgments. Psychometrika. doi:10.1007/s11336-022-09843-z PDF Journal Preprint Code & Data\nSäilynoja, T., Bürkner P. C., & Vehtari A. (2022). Graphical Test for Discrete Uniformity and its Applications in Goodness of Fit Evaluation and Multiple Sample Comparison. Statistics and Computing. doi:10.1007/s11222-022-10090-6 PDF Journal Preprint Code & Data\nCatalina A., Bürkner P. C., & Vehtari A. (2022). Projection Predictive Inference for Generalized Linear and Additive Multilevel Models. Artificial Intelligence and Statistics (AISTATS) Conference Proceedings. PDF Conference Preprint Software\nPavone, F., Piironen, J., Bürkner P. C., & Vehtari A. (2022). Using reference models in variable selection. Computational Statistics. doi:10.1007/s00180-022-01231-6 PDF Journal Preprint Code & Data\nSchad D. J., Nicenboim B., Bürkner P. C., Betancourt M., & Vasishth S. (2022). Workflow Techniques for the Robust Use of Bayes Factors. Psychological Methods. doi:10.1037/met0000472 PDF Journal Preprint Code & Data\nHeck, D., Boehm, U., Böing-Messing, F., Bürkner P. C., …, & Hoijtink, H. (2022). A Review of Applications of the Bayes Factor in Psychological Research. Psychological Methods. doi:10.1037/met0000454 PDF Journal Preprint\nMalén T., Karjalainen T., Isojärvi J., Vehtari A., Bürkner P. C., …, & Nummenmaa L. (2022). Age and sex dependent variability of type 2 dopamine receptors in the human brain: A large-scale PET cohort. NeuroImage. doi:10.1016/j.neuroimage.2022.119149 PDF Journal Preprint Code & Data\nPluhackova K., Schittny V., Bürkner P. C., Siligan C., & Horner A. (2022). Multiple Pore Lining Residues modulate Water Permeability of GlpF. Protein Science. doi:10.1002/pro.4431 PDF Journal\nGeorge J. P., Bürkner P. C., Sanders T., Neumann M., Cammalleri C., Vogt J., & Lang M. (2022). Long-term forest monitoring unravels constant mortality rise in European forests. Plant Biology. doi:10.1111/plb.13469 PDF Journal Code & Data\nSeaton F. M., Robinson D. A., Monteith D., Lebron I., Bürkner P. C., Tomlinson S., Emmett B. A., Smart S. M. (2022). Fifty years of reduction in sulphur deposition drives recovery in soil pH and plant communities. Journal of Ecology. doi:10.1111/1365-2745.14039 PDF Journal Preprint Code & Data\nFranke, L. K., Miedl, S. F., Danböck, S. K., Lohse, J., Liedlgruber, M., Bürkner P. C., Pletzer B., & Wilhelm, F. H. (2022). Estradiol during (analogue-)trauma: risk- or protective factor for intrusive re-experiencing? Psychoneuroendocrinology. doi:10.1016/j.psyneuen.2022.105819 PDF Journal Preprint\nJordon M., Smith P., Long P., Bürkner P. C., Petrokofsky G. & Willis K. (2022). Can Regenerative Agriculture increase national soil carbon stocks? Simulated country-scale adoption of reduced tillage, cover cropping, and ley-arable integration using RothC-26.3. Science of the Total Environment. doi:10.1016/j.scitotenv.2022.153955 PDF Journal Code & Data\nJordon M., Willis K., Bürkner P. C., & Petrokofsky G. (2022). Rotational grazing and multispecies herbal leys increase productivity in temperate pastoral systems – a meta-analysis. Agriculture, Ecosystems & Environment. doi:10.1016/j.agee.2022.108075 PDF Journal Code & Data\nJordon M., Willis K., Bürkner P. C., Haddaway N., Smith P., & Petrokofsky G. (2022). Temperate Regenerative Agriculture; a win-win for soil carbon and crop yield? Environmental Research Letters. doi:10.1088/1748-9326/ac8609 PDF Journal Preprint Code & Data\nNohe C., Hüffmeier J., Bürkner P. C., Mazei J., Sondern D., Runte A., Sieber F., & Hertel G. (2022). Unethical Choice in Negotiations: A Meta-Analysis on Gender Differences and Their Moderators. Organizational Behavior and Human Decision Processes. doi:10.1016/j.obhdp.2022.104189 PDF Journal Preregistration Code & Data\nMorina N., Seidemann J., Andor T., Sondern L., Bürkner P. C., Drenckhan I., & Buhlmann U. (2022). The effectiveness of cognitive behavioral therapy for social anxiety disorder in routine clinical practice. Clinical Psychology & Psychotherapy. doi:10.1002/cpp.2799 PDF Journal\nTeetzen, F., Bürkner P. C., Gregersen, S., & Vincent-Höper, S. (2022). The Mediating Effects of Work Characteristics on the Relationship between Transformational Leadership and Employee Well-Being: A Meta-Analytic Investigation. International Journal of Environmental Research and Public Health. doi:10.3390/ijerph19053133 PDF Journal\nKołczyńska M. & Bürkner P. C. (2022). Political trust as a cause and consequence of democracy: Longitudinal analysis of European data. SocArXiv preprint. doi:10.31235/osf.io/79dth PDF Preprint Code & Data"
  },
  {
    "objectID": "publications/index.html#section-3",
    "href": "publications/index.html#section-3",
    "title": "Scientific Publications",
    "section": "2021",
    "text": "2021\n\nBürkner P. C. (2021). Bayesian Item Response Modelling in R with brms and Stan. Journal of Statistical Software. doi:10.18637/jss.v100.i05 PDF Journal Preprint Software\nVehtari A., Gelman A., Simpson D., Carpenter B., & Bürkner P. C. (2021). Rank-normalization, folding, and localization: An improved Rhat for assessing convergence of MCMC (with discussion). Bayesian Analysis. doi:10.1214/20-BA1221 PDF Journal Preprint Code & Data\nRadev S. T., D’Alessandro M., Mertens U. K., Voss A., Köthe U., & Bürkner P. C. (2021). Amortized Bayesian Model Comparison with Evidental Deep Learning. IEEE Transactions on Neural Networks and Learning Systems. doi:10.1109/TNNLS.2021.3124052 PDF Journal Preprint Software\nPaananen T., Piironen, J., Bürkner P. C., & Vehtari A. (2021). Implicitly Adaptive Importance Sampling. Statistics and Computing. doi:10.1007/s11222-020-09982-2 PDF Journal Preprint Software\nCatalina A., Bürkner P. C., & Vehtari A. (2021). Latent space projection predictive inference. ArXiv preprint. doi:10.48550/arXiv.2109.04702 PDF Preprint Software\nWilliams, D. R., Rodriguez, J. E., & Bürkner P. C. (2021). Putting Variation into Variance: Modeling Between-Study Heterogeneity in Meta-Analysis. PsyArXiv preprint. doi:10.31234/osf.io/9vkqy PDF Preprint Code & Data\nDriebe, J. C., Sidari, M., Dufner, M., von der Heiden, J. M., Bürkner P. C., Penke, L., Zietsch B. P., & Arslan, R. C. (2021). Intelligence can be detected but is not found attractive in videos and live interactions. Evolution and Human Behavior. doi:10.1016/j.evolhumbehav.2021.05.002 PDF Journal Preprint Preregistration Code & Data\nKołczyńska M. & Bürkner P. C. (2021). Marketplace of indicators: Inconsistencies between country trends of measures of governance. Political Research Exchange. doi:10.1080/2474736X.2021.1989984 PDF Journal Preprint Code & Data\nModrák M., Bürkner P. C., Sieger T., …, Leos-Barajas V., Fiser K., & Hyanek T. (2021). Detailed disease progression of 213 patients hospitalized with Covid-19 in the Czech Republic: An exploratory analysis. PLOS ONE. doi:10.1371/journal.pone.0245103 PDF Journal Preprint Code & Data\nFranke, L. K., Rattel, J. A., Miedl, S. F., Danböck, S. K., Bürkner, P. C., & Wilhelm, F. H. (2021). Intrusive memories as conditioned responses to trauma cues: an empirically supported concept? Behaviour Research and Therapy. doi:10.1016/j.brat.2021.103848 PDF Journal Preprint\nDietel F., Möllmann A., Bürkner P. C., Wilhelm S., & Buhlmann U. (2021). Interpretation bias across body dysmorphic, social anxiety and generalized anxiety disorder – a multilevel, diffusion model account. Cognitive Therapy and Research. doi:10.1007/s10608-020-10180-7 PDF Journal Preprint Code & Data\nStecker J., Bürkner P. C., Hellmann J., Nestler S., & Back M. (2021). First Impressions of Refugees are More Strongly Influenced by Target Cues and Perceiver Attitudes Than by Sheer Group Affiliation. Collabora: Psychology. doi:10.1525/collabra.22160 PDF Journal Preprint Code & Data\nReynolds J. & Bürkner P. C. (2021). Examining the Relationship Between Weapon Type and Relationship Type in American Homicides: A Bayesian Approach. Homicide Studies. doi:10.1177/1088767920976191 PDF Journal Preprint Code & Data\nKuck, N., Cafitz, L., Bürkner, P. C., Nosthoff-Horstmann, L., Wilhelm, S., & Buhlmann, U. (2021). Body dysmorphic disorder and self-esteem: A meta-analysis. BMC Psychiatry. doi:10.1186/s12888-021-03185-3 PDF Journal Preprint Code & Data\nHoppen L. M., Kuck N., Bürkner P. C., Karin E., Wootton B. M., & Buhlmann, U. (2021). Low intensity technology-delivered cognitive behavioral therapy for obsessive-compulsive disorder: A meta-analysis. BMC Psychiatry. doi:10.1186/s12888-021-03272-5 PDF Journal Code & Data\nWinter, B. & Bürkner P. C. (2021). Poisson regression for linguists: A tutorial introduction to modeling count data with brms. Language and Linguistics Compass. doi:10.1111/lnc3.12439 PDF Journal Preprint Code & Data\nNohr, L., Bürkner P. C., Ruiz, A. L., Ferrer, J. E. S., Capponi, D., & Buhlmann, U. (2021). Social and cultural determinants of help-seeking in Cuba and Germany – A structural equation model approach. PsyArXiv preprint. doi:10.31234/osf.io/5tqwv PDF Preprint"
  },
  {
    "objectID": "publications/index.html#section-4",
    "href": "publications/index.html#section-4",
    "title": "Scientific Publications",
    "section": "2020",
    "text": "2020\n\nBürkner P. C., Gabry J., & Vehtari A. (2020). Approximate leave-future-out cross-validation for Bayesian time series models. Journal of Statistical Computation and Simulation. doi:10.1080/00949655.2020.1783262 PDF Journal Preprint Code & Data\nBürkner P. C., Gabry J., & Vehtari A. (2020). Efficient leave-one-out cross-validation for Bayesian non-factorized normal and Student-t models. Computational Statistics. doi:10.1007/s00180-020-01045-4 PDF Journal Preprint Code & Data\nBürkner P. C. & Charpentier E. (2020). Modelling monotonic effects of ordinal predictors in Bayesian regression models. British Journal of Mathematical and Statistical Psychology. doi:10.1111/bmsp.12195 PDF Journal Preprint Code & Data\nBürkner P. C. (2020). Analysing Standard Progressive Matrics (SPM-LS) with Bayesian Item Response Models. Journal of Intelligence. doi:10.3390/jintelligence8010005 PDF Journal Preprint Code & Data\nHartmann M., Agiashvili G., Bürkner P. C., & Klami A. (2020). Flexible Prior Elicitation via the Prior Predictive Distribution. Uncertainty in Artificial Intelligence (UAI) Conference Proceedings. PDF Conference Preprint\nRadev S. T., Wieschen E. M., Voss A., & Bürkner P. C. (2020). Amortized Bayesian Inference for Models of Cognition. International Conference on Cognitive Modelling (ICCM) Conference Proceedings. PDF Conference Preprint\nSchulte N., Holling H., & Bürkner P. C. (2020). Can High-Dimensional Questionnaires Resolve the Ipsativity Issue of Forced-Choice Response Formats? Educational and Psychological Measurement. doi:10.1177/0013164420934861 PDF Journal Preprint Code & Data\nGelman A., Vehtari A., Simpson D., …, Bürkner P. C., & Modrák M. (2020). Bayesian Workflow. ArXiv preprint. doi:10.48550/arXiv.2011.01808 PDF Preprint\nPaananen T., Catalina A., Bürkner P. C., & Vehtari A. (2020). Group Heterogeneity Assessment for Multilevel Models. ArXiv preprint. doi:10.48550/arXiv.2005.02773 PDF Preprint Code & Data\nTrempler, I., Bürkner P. C., El-Sourani N., Binder E., Reker P., Fink G. R., & Schubotz R. (2020). Impaired context-sensitive adjustment of behaviour in Parkinson’s disease patients tested on and off medication: an fMRI study. NeuroImage. doi:10.1016/j.neuroimage.2020.116674 PDF Journal Code & Data\nLandmeyer N. C., Bürkner P. C., Wiendl H., Ruck T., Hartung H. P., Holling H., Meuth S. G., & Johnen A. (2020). Disease-modifying treatments and cognition in relapsing-remitting multiple sclerosis: A meta-analysis. Neurology. doi:10.1212/WNL.0000000000009522 PDF Journal Code & Data\nDietel F., Zache C., Bürkner P. C., Schulte J., Möbius M., Bischof A., Wilhelm S., & Buhlmann U. (2020). Internet-based Interpretation Bias Modification for body dissatisfaction: A three-armed randomized controlled trial. International Journal of Eating Disorders. doi:10.1002/eat.23280 PDF Journal Preprint Code & Data\nDeres T., Bürkner P. C., Klauke B., & Buhlmann U. (2020). The Role of Stigma during the Course of Inpatient Psychotherapeutic Treatment in a German Sample. Clinical Psychology and Psychotherapy. doi:10.1002/cpp.2423 PDF Journal Code & Data\nBusch, L., Utesch, T., Bürkner P. C., & Strauss, B. (2020). The Influence of Fitness-App Usage on Psychological Well-Being and Body Awareness—A Daily Diary Randomized Trial. Journal of Sport & Exercise Psychology. doi:10.1123/jsep.2019-0315 PDF Journal Preprint Code & Data\nWilliams D. R. & Bürkner P. C. (2020). Coding errors lead to unsupported conclusions: A critique of Hofmann et al. (2015). Meta-Psychology. doi:10.15626/MP.2018.872 PDF Journal Report Code & Data\nHossiep R., Harnack, K., & Bürkner P. C. (2020). Goal setting in distributive and integrative negotiations: a meta-analysis. PsyArXiv preprint. doi:10.31234/osf.io/mkgxt PDF Preprint Code & Data"
  },
  {
    "objectID": "publications/index.html#section-5",
    "href": "publications/index.html#section-5",
    "title": "Scientific Publications",
    "section": "2019",
    "text": "2019\n\nBürkner P. C., Schulte N., & Holling H. (2019). On the Statistical and Practical Limitations of Thurstonian IRT Models. Educational and Psychological Measurement. doi:10.1177/0013164419832063 PDF Journal Preprint Code & Data\nBürkner P. C. & Vuorre, M. (2019). Ordinal Regression Models in Psychology: A Tutorial. Advances in Methods and Practices in Psychological Science. doi:10.1177/2515245918823199 PDF Journal Preprint Code & Data\nBürkner P. C. (2019). thurstonianIRT: Thurstonian IRT Models in R. Journal of Open Source Software. doi:10.21105/joss.01662 PDF Journal Software\nChen G., Bürkner P. C., Taylor P. A., Li Z., Yin L., Glen D. R., Kinnison J. K., Cox R. W., & Pessoa L. (2019). An Integrative Approach to Matrix-Based Analyses in Neuroimaging Connectomics. Human Brain Mapping. doi:10.1002/hbm.24686 PDF Journal Preprint\nNalborczyk, L., Batailler, C., Loevenbruck H., Vilain, A., & Bürkner P. C. (2019). An Introduction to Bayesian Multilevel Models Using brms: A Case Study of Gender Effects on Vowel Variability in Standard Indonesian. Journal of Speech, Language, and Hearing Research. doi:10.1044/2018_JSLHR-S-18-0006 PDF Journal Preprint Code & Data\nZetsche, U., Bürkner P. C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology. doi:10.1037/abn0000452 PDF Journal Preprint Code & Data\nNalborczyk, L., Bürkner P. C., & Williams D. (2019). Pragmatism should not be a substitute for statistical literacy, a commentary on Albers, Kiers, and van Ravenzwaaij (2018). Collabora: Psychology. doi:10.1525/collabra.197 PDF Journal Preprint Code & Data\nBeisemann M., Forthmann B., Bürkner P. C., & Holling H. (2019). Psychometric Evaluation of an Alternate Scoring for the Remote Associates Test. The Journal of Creative Behavior. PDF Journal\nForthmann, B., Bürkner P. C., Benedek, M., Szardenings, C., & Holling, H. (2019). A New Perspective on the Multidimensionality of Divergent Thinking Tasks. Frontiers in Psychology: Cognition. doi:10.3389/fpsyg.2019.00985 PDF Journal Preprint Code & Data\nSchuler, B. A., Binnewies, C., & Bürkner P. C. (2019). The Relationship Between Job Crafting, Work Engagement, and Performance: A Meta-Analysis. PsyArXiv preprint. doi:10.31234/osf.io/xpf2v PDF Preprint"
  },
  {
    "objectID": "publications/index.html#section-6",
    "href": "publications/index.html#section-6",
    "title": "Scientific Publications",
    "section": "2018",
    "text": "2018\n\nBürkner P. C., Schwabe S., & Holling H. (2018). Optimal Designs for the Generalized Partial Credit Model. British Journal of Mathematical and Statistical Psychology. doi:10.1111/bmsp.12148 PDF Journal Preprint\nBürkner P. C. (2018). Advanced Bayesian Multilevel Modeling with the R Package brms. The R Journal. doi:10.32614/RJ-2018-017 PDF Journal Preprint Software Code\nJohnen A., Bürkner P. C., Landmeyer N. C., …, & Salmen A. (2018). Can we predict cognitive decline after initial diagnosis of multiple sclerosis? – Results from the German National early MS cohort (KKNMS). Journal of Neurology. doi:10.1007/s00415-018-9142-y PDF Journal\nQuante L., Kluger S., Bürkner P. C., Ekman M., & Schubotz R. (2018). Graph measures in task-based fMRI: functional integration during read-out of visual and auditory information. PLOS ONE. doi:10.1371/journal.pone.0207119 PDF Journal\nZetsche U., Bürkner P. C., & Schulze L. (2018). Shedding light on the association between repetitive negative thinking and deficits in cognitive control – a meta-analysis. Clinical Psychology Review. doi:10.1016/j.cpr.2018.06.001 PDF Journal Preprint Code & Data\nRathgeber M., Bürkner P. C., Schiller E. M., & Holling H. (2018). The Efficacy of Emotionally Focused Therapy and Behavioral Couples Therapy: A Meta-Analysis. Journal of Marital and Family Therapy. doi:10.1111/jmft.12336 PDF Journal\nSchneider I., Kugel H., Redlich R., Grotegerd D., Bürger C., Bürkner P. C., …, Dannlowski U., & Hohoff C. (2018). Association of serotonin transporter gene AluJb methylation with major depression, amygdala responsiveness, 5-HTTLPR/rs25531 polymorphism, and stress. Neuropsychopharmacology. doi:10.1038/npp.2017.273 PDF Journal\nReinhold M., Bürkner P. C., Holling H. (2018). Effects of Expressive Writing on Depressive Symptoms – A Meta-Analysis. Clinical Psychology: Science and Practice. doi:10.1111/cpsp.12224 PDF Journal\nZhou T., Popescu S. C., Lawing A. M., Eriksson M., Strambu B., Bürkner P. C. (2018). Bayesian and classical machine learning methods: A comparison for tree species classification with LiDAR waveform signatures. Remote Sensing. doi:10.3390/rs10010039 PDF Journal\nSchulze L., Bürkner P. C., Bohländer J., & Zetsche U. (2018). Cognitive control and daily affect regulation in major depression and borderline personality disorder: protocol for an experimental ambulatory assessment study in Berlin, Germany. BMJ Open. doi:10.1136/bmjopen-2018-022694 PDF Journal Code & Data\nArslan R. C., Willführ K. P., Frans E. M., Verweij K. J. H., Bürkner P. C., Myrskylä M., Voland E., Almqvist C., Brendan P., Zietsch B. P., & Penke L. (2018). Relaxed selection and mutation accumulation are best studied empirically: Reply to a comment by Woodley et al. Proceedings of the Royal Society B. doi:10.1098/rspb.2018.0092 PDF Journal\nWilliams D. R., Rast P., & Bürkner P. C. (2018). Bayesian Meta-Analysis with Weakly Informative Prior Distributions. PsyArXiv preprint. doi:10.31234/osf.io/7tbrm PDF Preprint Code & Data\nFleischer C., Doebler P., Bürkner P. C. & Holling H. (2018). Adventure therapy effects on self-concept – A meta-analysis. PsyArXiv preprint. doi:10.31234/osf.io/c7y9a PDF Preprint Code & Data"
  },
  {
    "objectID": "publications/index.html#section-7",
    "href": "publications/index.html#section-7",
    "title": "Scientific Publications",
    "section": "2017",
    "text": "2017\n\nBürkner P. C. (2017). brms: An R Package for Bayesian Multilevel Models using Stan. Journal of Statistical Software. doi:10.18637/jss.v080.i01 PDF Journal Software\nBürkner P. C., Williams D. R., Simmons T. C., & Woolley J. D. (2017). Intranasal oxytocin may improve high-level social cognition in schizophrenia, but not social cognition or neurocognition in general: A multi-level Bayesian meta-analysis. Schizophrenia Bulletin. doi:10.1093/schbul/sbx053 PDF Journal Code & Data\nBürkner P. C., Bittner N., Holling H., & Buhlmann U. (2017). D-Cycloserine Augmentation of Behavior Therapy for Anxiety and Obsessive-Compulsive Disorders: A Meta-Analysis. PLOS ONE. doi:10.1371/journal.pone.0173660 PDF Journal Code & Data\nCarlsson R., Schimmack U., Williams D. R., & Bürkner P. C. (2017). Bayes Factors From Pooled Data Are No Substitute for Bayesian Meta-Analysis: Commentary on Scheibehenne, Jamil, and Wagenmakers (2016). Psychological Science. doi:10.1177/0956797616684682 PDF Journal Code & Data\nArslan R. C., Willführ K. P., Frans E. M., Verweij K. J. H., Bürkner P. C., Myrskylä M., Voland E., Almqvist C., Brendan P., Zietsch B. P., & Penke L. (2017). Older fathers’ children have lower evolutionary fitness across four centuries and in four populations. Proceedings of the Royal Society B. doi:10.1098/rspb.2017.1562 PDF Journal Code & Data\nJohnen A., Landmeyer N. C., Bürkner P. C., Wiendl H., Meuth S. G., & Holling H. (2017). Distinct cognitive impairments in different disease courses of multiple sclerosis - A systematic review and meta-analysis. Neuroscience & Biobehavioral Reviews. doi:10.1016/j.neubiorev.2017.09.005 PDF Journal\nWilliams D. R., Carlsson R., & Bürkner P. C. (2017). Between-litter variation in developmental studies of hormones and behavior: inflated false positives and diminished power. Frontiers in Neuroendocrinology. doi:10.1016/j.yfrne.2017.08.003 PDF Journal Code & Data\nWilliams D. R. & Bürkner P. C. (2017). Effects of intranasal oxytocin on symptoms of schizophrenia: A multivariate Bayesian meta-analysis. Psychoneuroendocrinology. doi:10.1016/j.psyneuen.2016.10.013 PDF Journal Code & Data\nWilliams D. R. & Bürkner P. C. (2017). Data extraction and statistical errors: A quantitative critique of Gumley et al. (2014). British Journal of Clinical Psychology. doi:10.1111/bjc.12130 PDF Journal Code & Data"
  },
  {
    "objectID": "publications/index.html#section-8",
    "href": "publications/index.html#section-8",
    "title": "Scientific Publications",
    "section": "2016",
    "text": "2016\n\nBürkner P. C., Doebler P., & Holling H. (2016). Optimal design of the Wilcoxon-Mann-Whitney-test. Biometrical Journal. doi:10.1002/bimj.201600022 PDF Journal Preprint\nBenda N., Bürkner P. C., Freise F., Holling H., & Schwabe R. (2016). Adaptive Designs for Quantal Dose-Response Experiments with False Answers. Journal of Statistical Theory and Practice. doi:10.1080/15598608.2016.1213209 PDF Journal"
  },
  {
    "objectID": "publications/index.html#section-9",
    "href": "publications/index.html#section-9",
    "title": "Scientific Publications",
    "section": "2014",
    "text": "2014\n\nBürkner P. C. & Doebler P. (2014). Testing for Publication Bias in Diagnostic Meta-Analysis: A Simulation Study. Statistics in Medicine. doi:10.1002/sim.6177 PDF Journal Preprint"
  },
  {
    "objectID": "theses/index.html",
    "href": "theses/index.html",
    "title": "Thesis Topics",
    "section": "",
    "text": "In our lab, we have open topics for Bachelor and Master theses throughout the entire academic year. Most of them are part of one of our larger research projects. Below, you can find a short description of some selected topics. If one of the them sounds interesting to you, please contact the person mentioned under Supervision (just click on their name to be forwarded to their profile) and put me in CC. In your email, please don’t forget to provide some basic information about yourself, including your field of study, programming skills, and completed courses that you think may be relevant. If none of the topics below fits your interests, but you still want to write your thesis with us, please contact me directly. We are also open for your own ideas should they be something we can properly supervise.\n\n\n\n\n\n\nThe influence of base distributions in normalizing flows on method performance\n\n\n\n\n\nSupervision: Florence Bockting\nProject: Simulation-Based Prior Distributions for Bayesian Models\nImportant References:\n\nBockting, F., Radev, S. T., & Bürkner, P. C. (2024). Simulation-based prior knowledge elicitation for parametric Bayesian models. Scientific Reports, 14(1), 17330. Link\nKobyzev, I., Prince, S. J., & Brubaker, M. A. (2020). Normalizing flows: An introduction and review of current methods. IEEE transactions on pattern analysis and machine intelligence, 43(11), 3964-3979. Link\n\nTools: Python, TensorFlow\nProblem description: In one of our recent methods, we use normalizing flows to learn a joint prior distribution for the parameters in a Bayesian model. A normalizing flow transforms a simple probability distribution (base distribution) into a complex target distribution (in our case the joint prior). A common choice for the base distribution is a standard Gaussian. We want to investigate different specifications of the base distribution and check their influence on the learned joint prior when compared to a specific ground truth. This project refers to the areas: method development, method implementation.\nProject structure:\n\nUnderstanding the problem (literature work on normalizing flows)\nSpecify and motivate different base distributions; explain your expectations (methodological work)\nImplement and run a simulation study (in Python using TensorFlow)\ndiscuss the results and provide recommendations\n\n\n\n\n\n\n\n\n\n\nImplementation of normalizing flows in Stan\n\n\n\n\n\nSupervision: Florence Bockting\nProject: Simulation-Based Prior Distributions for Bayesian Models\nImportant References:\n\nBockting, F., Radev, S. T., & Bürkner, P. C. (2024). Simulation-based prior knowledge elicitation for parametric Bayesian models. Scientific Reports, 14(1), 17330. Link\n\nTools: Stan, Python, TensorFlow\nProblem description: In one of our recent methods, we use normalizing flows (NFs) to learn a joint prior distribution for the parameters in a Bayesian model. The advantage of NFs is that they learn a closed form analytic function that we can use as prior for a Bayesian model. The learning algorithm is implemented in Python with TensorFlow. To make use of the learned joint prior distribution in probabilistic models implemented in Stan, we need an implementation of NFs in Stan. This project refers to the area: method implementation.\nProject structure:\n\nUnderstanding the problem (literature work on normalizing flows; implementation of project in Python)\nConceptual work on a potential implementation in Stan\nImplementation in Stan\nRun some test examples and discuss results\n\n\n\n\n\n\n\n\n\n\nVariational methods for structural equation models\n\n\n\n\n\nSupervision: Luna Fazio\nProject: Bayesian Distributional Latent Variable Models\nImportant references:\n\nGaussian distributional structural equation models: A framework for modeling latent heteroscedasticity\nVariational Bayes for Mixture of Gaussian Structural Equation Models\n\nTools: R, Stan\nProblem description: Bayesian estimation of structural equation models is more flexible than the frequentist counterpart, but can be significantly slower. Variational methods provide fast approximate model fits, but their performance needs to be assessed systematically to determine when they can be reliably used.\nProject structure:\n\nReview relevant concepts and literature.\nSet up an appropriate computational environment for simulation studies.\nReplicate previously published results.\nExtend prior work with additional simulations on models and variational algorithms that have not yet been assessed.\nAnalyze and discuss results.\n\n\n\n\n\n\n\n\n\n\nLagged modeling using composite Gaussian processes\n\n\n\n\n\nSupervision: Soham Mukherjee\nProject: Probabilistic Models for Single-Cell RNA Sequencing Data\nTools: R, Stan\nRelevant literature:\n\nGaussian Processes for Machine Learning\nModelling transcriptional regulation using Gaussian processes\n\nProblem description: Composite Gaussian processes (GPs) allow a natural framework for modeling two or more related data generating processes simultaneously by specifying a joint GP distribution. A specific interesting case would be a composite process of two related GPs expressed through a shared input space. A direct application here would be to model spliced and its time-lagged unspliced RNA expression levels as response using a common cellular ordering as inputs. The primary challenge is to verify if composite GPs are a suitable mathematical framework to model such cases of strictly related data generating processes.\nProject structure:\n\nLiterature review and understanding of GPs and composite GPs.\nModel implementation for composite GPs in Stan.\nSimulation studies for model validation.\nApplications to example case studies using single-cell data.\n\n\n\n\n\n\n\n\n\n\nAmortized forecasting models\n\n\n\n\n\nSupervision: Šimon Kucharský\nProject: Applications of Amortized Bayesian Inference\nImportant references:\n\nJANA: Jointly Amortized Neural Approximation of Complex Bayesian Models (and related BayesFlow articles)\nForecasting at scale\n\nTools: Python, Stan\nProblem description: Forecasting with Bayesian models is becoming more popular. Some forecasting applications require making predictions at scale. Traditional Bayesian methods (MCMC) may be too slow for such applications. Amortization can solve this issue as it can be considerable faster during inference (forecasting) than MCMC, while providing the full Bayesian estimate.\nProject structure:\n\nReview relevant concepts and literature.\nGet familiarized with BayesFlow.\nSelect a subset of the model features provided by Prophet and implement it with BayesFlow for amortized forecasting.\nValidate the model.\nAnalyze and discuss results.\n\n\n\n\n\n\n\n\n\n\nAmortized hierarchical mixture models\n\n\n\n\n\nSupervision: Šimon Kucharský Daniel Habermann\nProjects:\nApplications of Amortized Bayesian Inference Amortized Bayesian Inference for Multilevel Models\nImportant references:\n\nJANA: Jointly Amortized Neural Approximation of Complex Bayesian Models (and related BayesFlow articles)\nFinite Mixture Models (or any other literature on mixture models)\nBayesian Hierarchical Models (or any hierarchical models literature)\n\nTools: Python, Stan\nProblem description: BayesFlow was recently expanded to handle two level hierarchical models (for details, talk to Daniel) and is being expanded to be able to make inferences for mixture models (for details, talk to Simon). The idea for this project is to combine the two approaches and investigate how to implement amortized inference for hierarchical mixture models with BayesFlow.\nProject structure:\n\nReview relevant concepts and literature.\nGet familiarized with BayesFlow and the current implementation of hierarchical and mixture models.\nImplement a basic hierarchical mixture model with BayesFlow as a proof of concept.\nValidate the model.\nAnalyze and discuss results.\n\n\n\n\n\n\n\n\n\n\nStable diffusion for BayesFlow\n\n\n\n\n\nSupervision: Lars Kühmichel\nProject: BayesFlow: Simulation Intelligence with Deep Learning\nTools: Python, Keras3\nRelevant Literature:\n\nDenoising Diffusion\nStable Diffusion\nBayesFlow\n\nProblem Description: BayesFlow is a Python library for simulation-based amortized Bayesian inference with neural networks. It aims to provide users with a rich collection of neural network architectures. Diffusion Models are a modern and powerful type of generative neural network that particularly excel at creating high-quality samples, even for complex, high-dimensional distributions.\nProject structure:\n\nLiterature search on amortized Bayesian inference and Diffusion Models\nDraft your own first implementation of Stable Diffusion\nUse your implementation to reproduce a generative deep learning paper\nPort your implementation into BayesFlow\nUse your ported implementation to reproduce an amortized Bayesian inference paper\n\n\n\n\n\n\n\n\n\n\nJoint prior distributions for hierarchical phylogenetic models\n\n\n\n\n\nSupervision: Paul Bürkner\nRelevant literature:\n\nEstimating Phylogenetic Multilevel Models with brms\n\nTools: R, Stan\nProblem description: Phylogenetic trees are used to represent the evolutionary history between a set of species. The implied dependencies between species can be expressed statistically via phylogenetic models. However, these models are often hard to estimate and may require strong prior knowledge, which we express in Bayesian statistics via prior distributions. The goal of this thesis is to implement and evaluate joint prior distributions for the variance parameters of phylogenetic models. We have concrete ideas for such priors, which we will discuss with you upon starting your thesis.\nProject structure:\n\nLiterature search on priors for phylogenetic models\nImplement the new and existing priors in Stan\nRun simulation studies\nAnalyse and discuss results\n\n\n\n\n\n\n\n\n\n\nImpact of shrinkage priors on strong signals\n\n\n\n\n\nSupervision: Javier Enrique Aguilar\nProject: Intuitive Joint Priors for Bayesian Multilevel Models\nRelevant literature:\n\nSparsity information and regularization in the horseshoe and other shrinkage priors\n\nTools: R, Stan\nProblem description: Continuous global-local shrinkage priors have gained significant traction in Bayesian statistics due to their ability to enhance predictive performance while decreasing bias. In this study, we aim to conduct an analysis of how several well-known shrinkage priors target and shrink strong signals within the data.\nProject structure:\n\nFamiliarize yourself with shrinkage priors\nCharacterize the shrinkage on strong signals\nCarry out simulations\nAnalyse and discuss the results"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Paul Bürkner",
    "section": "",
    "text": "Email\n  \n  \n    \n     GitHub\n  \n  \n      Google Scholar\n  \n  \n      Bluesky\n  \n\n  \n  \nI am a statistician with a focus on probabilistic (Bayesian) methods currently working as a Full Professor of Computational Statistics at TU Dortmund University, Department of Statistics. Having originally studied psychology and mathematics, my core research is nowadays located somewhere between statistics and machine learning, with applications in almost all quantitative sciences.\nThe Bayesian approach to data analysis provides a powerful way to handle uncertainty in all observations, model parameters, and model structure using probability theory. Thus, it should not come as a surprise that Bayesian methods are increasingly used in statistical and computational inference in both science and industry. Probabilistic programming languages make it easier to specify and fit Bayesian models, but this still leaves us with many options regarding constructing, evaluating, and using these models, along with many remaining challenges in computation. In my lab, we are working on a wide range of research topics related to the development, estimation, evaluation, implementation, or application of Bayesian methods. This includes, among others, uncertainty quantification, prior specification, simulation-based inference, as well as model comparison.\nIf you are a scientist who wants to collaborate with me, a PhD student or PostDoc candidate interested in my research, or a student looking for a thesis topic, please reach out to me! Please also check out the open positions in my lab, which additionally includes a list of thesis topics for Bachelor and Master students."
  },
  {
    "objectID": "software/index.html",
    "href": "software/index.html",
    "title": "Open Source Software",
    "section": "",
    "text": "In addition to doing research and managing a lab, I am deeply involved in open source software development. While I mostly program in R myself, my lab uses a flexible combination of R, Python, and C++. I also hope to add Julia to the list soon. Below, you can find an overview of my most important open source software contributions."
  },
  {
    "objectID": "software/index.html#brms",
    "href": "software/index.html#brms",
    "title": "Open Source Software",
    "section": "brms",
    "text": "brms\n\n\n\n\n\nbrms: Bayesian Regression Models Using Stan\nMy role: Lead author and maintainer\nWebsite GitHub Forums Book Blog-Posts\n\n\nbrms is an R package to fit Bayesian generalized (non-)linear multilevel models using Stan. The formula syntax provides a powerful combination of intuitiveness and flexibility. A wide range of response distributions are supported, allowing users to fit many differents kinds of models including linear, robust linear, count data, survival, response times, ordinal, zero-inflated, and even self-defined mixture models all in a multilevel context. Further modeling options include theory- and data-driven non-linear functions, auto-correlation structures, censored data, missing value imputation, and quite a few more. In addition, all parameters of the response distribution can be predicted in order to perform distributional regression. Multivariate models (i.e., models with multiple response variables) can be fit as well. Prior specifications are flexible and explicitly encourage users to apply prior distributions that actually reflect their knowledge. Model fit can easily be assessed and compared with posterior predictive checks, cross-validation, and Bayes factors.\nSelected References:\n\nBürkner P. C. (2021). Bayesian Item Response Modelling in R with brms and Stan. Journal of Statistical Software. doi:10.18637/jss.v100.i05 PDF Journal Preprint\nBürkner P. C. (2018). Advanced Bayesian Multilevel Modeling with the R Package brms. The R Journal. doi:10.32614/RJ-2018-017 PDF Journal Preprint\nBürkner P. C. (2017). brms: An R Package for Bayesian Multilevel Models using Stan. Journal of Statistical Software. doi:10.18637/jss.v080.i01 PDF Journal"
  },
  {
    "objectID": "software/index.html#stan",
    "href": "software/index.html#stan",
    "title": "Open Source Software",
    "section": "Stan",
    "text": "Stan\n\n\n\n\n\nStan: A Probabilistic Programming Language\nMy role: Development team member\nWebsite GitHub Forums\n\n\nStan is a state-of-the-art platform for statistical modeling and high-performance statistical computation. Thousands of users rely on Stan for statistical modeling, data analysis, and prediction in the social, biological, and physical sciences, engineering, and business. Users specify log density functions in Stan’s probabilistic programming language and get full Bayesian statistical inference with MCMC sampling as well as access to other inference algorithms. Stan’s math library provides differentiable probability functions & linear algebra (C++ autodiff). Additional R packages provide expression-based linear modeling, posterior visualization, Bayesian cross-validation, and much more.\nStan interfaces with the most popular data analysis languages (R, Python, Julia) as well as the command line. It runs on all major platforms (Linux, Mac, Windows). Stan is freedom-respecting, open-source software (new BSD core, some interfaces GPLv3). Stan is associated with NumFOCUS, a nonprofit supporting open code and reproducible science, through which you can help support Stan.\nSelected References:\n\nStan Development Team (current year). Stan Modeling Language Users Guide and Reference Manual (current version). Website Manual\nCarpenter B., Gelman A., Hoffman M. D., Lee D., Goodrich B., Betancourt M., Brubaker M., Guo J., Li P., and Riddell A. (2017). Stan: A probabilistic programming language. Journal of Statistical Software. doi:10.18637/jss.v076.i01 Journal\n\n\nStan-related libraries\nWithin the Stan universe, I have worked on many different software libraries.\nLead author of\n\nbrms: Bayesian regression models using Stan Website GitHub Blog-Posts\nposterior: Tools for working with posterior distributions GitHub\n\nAuthor of\n\nposteriordb: A database of Bayesian posterior inference GitHub\nloo: Approximate leave-one-out cross-validation Website GitHub\n\nContributed to\n\nrstan: R Interface to Stan Website GitHub\nbayesplot: Plotting Bayesian models Website GitHub\nprojpred: Projection predictive variable selection Website GitHub"
  },
  {
    "objectID": "software/index.html#bayesflow",
    "href": "software/index.html#bayesflow",
    "title": "Open Source Software",
    "section": "BayesFlow",
    "text": "BayesFlow\n\n\n\n\n\nBayesFlow: Amortized Bayesian Workflows With Neural Networks\nMy role: Development team member\nWebsite GitHub Forums\n\n\nBayesFlow is a Python library for efficient simulation-based Bayesian Inference. It enables users to create specialized neural networks for amortized Bayesian inference, which repays users with rapid statistical inference after a potentially longer simulation-based training phase. A cornerstone idea of amortized Bayesian inference is to employ generative neural networks for parameter estimation, model comparison, and model validation when working with intractable simulators whose behavior as a whole is too complex to be described analytically.\nBoth the BayesFlow library itself and its community are quickly growing. Our goal is to make it the gold-standard simulation-based inference library within the next couple of years.\nSelected References:\n\nRadev S. T., Schmitt M., Schumacher L., Elsemüller L., Pratz V., Schälte Y., Köthe U., & Bürkner P. C. (2023). BayesFlow: Amortized Bayesian Workflows With Neural Networks. Journal of Open Source Software. doi:10.21105/joss.05702 PDF Journal Preprint\nRadev S. T., Schmitt M., Pratz V., Picchini U., Köthe U., & Bürkner P. C. (2023). JANA: Jointly Amortized Neural Approximation of Complex Bayesian Models. Uncertainty in Artificial Intelligence (UAI) Conference Proceedings. PDF Conference Preprint\nSchmitt, M., Bürkner P. C., Köthe U., & Radev S. T. (2023). Detecting Model Misspecification in Amortized Bayesian Inference with Neural Networks. Proceedings of the German Conference on Pattern Recognition (GCPR). doi:10.1007/978-3-031-54605-1_35 PDF Conference Preprint\nRadev S. T., D’Alessandro M., Mertens U. K., Voss A., Köthe U., & Bürkner P. C. (2021). Amortized Bayesian Model Comparison with Evidental Deep Learning. IEEE Transactions on Neural Networks and Learning Systems. doi:10.1109/TNNLS.2021.3124052 PDF Journal Preprint\nRadev, S. T., Mertens, U. K., Voss, A., Ardizzone, L., & Köthe, U. (2020). BayesFlow: Learning complex stochastic models with invertible neural networks. IEEE Transactions on Neural Networks and Learning Systems. doi:10.1109/TNNLS.2020.3042395 Journal Preprint"
  },
  {
    "objectID": "software/index.html#other-software",
    "href": "software/index.html#other-software",
    "title": "Open Source Software",
    "section": "Other Software",
    "text": "Other Software\nLead author of\n\nthurstonianIRT: Fit Thurstonian IRT models in R GitHub\n\nAuthor of\n\nggsimplex: Simplex visualizations with ggplot2 GitHub\nbayesim: Simulations for Bayesian models GitHub\nbayeshear: Metrics for evaluating Bayesian models GitHub\nbayesfam: Custom families for brms GitHub\nbayesian: An interface from brms to tidymodels Website GitHub\n\nContributed to:\n\nemmeans: Estimating marginal means GitHub"
  },
  {
    "objectID": "impressum/index.html",
    "href": "impressum/index.html",
    "title": "Impressum",
    "section": "",
    "text": "Kontakt:\npaul /dott/ buerkner /ett/ gmail /dott/ com\n\n\nVerantwortlich für den Inhalt nach § 55 Abs. 2 RStV:\nPaul-Christian Bürkner  Weimarstr. 19 70176 Stuttgart \n\n\nHaftungsausschluss:\nHaftung für Inhalte Die Inhalte unserer Seiten wurden mit größter Sorgfalt erstellt. Für die Richtigkeit, Vollständigkeit und Aktualität der Inhalte können wir jedoch keine Gewähr übernehmen. Als Diensteanbieter sind wir gemäß § 7 Abs.1 TMG für eigene Inhalte auf diesen Seiten nach den allgemeinen Gesetzen verantwortlich. Nach §§ 8 bis 10 TMG sind wir als Diensteanbieter jedoch nicht verpflichtet, übermittelte oder gespeicherte fremde Informationen zu überwachen oder nach Umständen zu forschen, die auf eine rechtswidrige Tätigkeit hinweisen. Verpflichtungen zur Entfernung oder Sperrung der Nutzung von Informationen nach den allgemeinen Gesetzen bleiben hiervon unberührt. Eine diesbezügliche Haftung ist jedoch erst ab dem Zeitpunkt der Kenntnis einer konkreten Rechtsverletzung möglich. Bei Bekanntwerden von entsprechenden Rechtsverletzungen werden wir diese Inhalte umgehend entfernen.\nHaftung für Links Unser Angebot enthält Links zu externen Webseiten Dritter, auf deren Inhalte wir keinen Einfluss haben. Deshalb können wir für diese fremden Inhalte auch keine Gewähr übernehmen. Für die Inhalte der verlinkten Seiten ist stets der jeweilige Anbieter oder Betreiber der Seiten verantwortlich. Die verlinkten Seiten wurden zum Zeitpunkt der Verlinkung auf mögliche Rechtsverstöße überprüft. Rechtswidrige Inhalte waren zum Zeitpunkt der Verlinkung nicht erkennbar. Eine permanente inhaltliche Kontrolle der verlinkten Seiten ist jedoch ohne konkrete Anhaltspunkte einer Rechtsverletzung nicht zumutbar. Bei Bekanntwerden von Rechtsverletzungen werden wir derartige Links umgehend entfernen.\nUrheberrecht Die durch die Seitenbetreiber erstellten Inhalte und Werke auf diesen Seiten unterliegen dem deutschen Urheberrecht. Die Vervielfältigung, Bearbeitung, Verbreitung und jede Art der Verwertung außerhalb der Grenzen des Urheberrechtes bedürfen der schriftlichen Zustimmung des jeweiligen Autors bzw. Erstellers. Downloads und Kopien dieser Seite sind nur für den privaten, nicht kommerziellen Gebrauch gestattet. Soweit die Inhalte auf dieser Seite nicht vom Betreiber erstellt wurden, werden die Urheberrechte Dritter beachtet. Insbesondere werden Inhalte Dritter als solche gekennzeichnet. Sollten Sie trotzdem auf eine Urheberrechtsverletzung aufmerksam werden, bitten wir um einen entsprechenden Hinweis. Bei Bekanntwerden von Rechtsverletzungen werden wir derartige Inhalte umgehend entfernen.\nDatenschutz Die Nutzung unserer Webseite ist in der Regel ohne Angabe personenbezogener Daten möglich. Soweit auf unseren Seiten personenbezogene Daten (beispielsweise Name, Anschrift oder eMail-Adressen) erhoben werden, erfolgt dies, soweit möglich, stets auf freiwilliger Basis. Diese Daten werden ohne Ihre ausdrückliche Zustimmung nicht an Dritte weitergegeben. Wir weisen darauf hin, dass die Datenübertragung im Internet (z.B. bei der Kommunikation per E-Mail) Sicherheitslücken aufweisen kann. Ein lückenloser Schutz der Daten vor dem Zugriff durch Dritte ist nicht möglich. Der Nutzung von im Rahmen der Impressumspflicht veröffentlichten Kontaktdaten durch Dritte zur Übersendung von nicht ausdrücklich angeforderter Werbung und Informationsmaterialien wird hiermit ausdrücklich widersprochen. Die Betreiber der Seiten behalten sich ausdrücklich rechtliche Schritte im Falle der unverlangten Zusendung von Werbeinformationen, etwa durch Spam-Mails, vor.\nGoogle Analytics Diese Website benutzt Google Analytics, einen Webanalysedienst der Google Inc. (‘’Google’‘). Google Analytics verwendet sog.’‘Cookies’’, Textdateien, die auf Ihrem Computer gespeichert werden und die eine Analyse der Benutzung der Website durch Sie ermöglicht. Die durch den Cookie erzeugten Informationen über Ihre Benutzung dieser Website (einschließlich Ihrer IP-Adresse) wird an einen Server von Google in den USA übertragen und dort gespeichert. Google wird diese Informationen benutzen, um Ihre Nutzung der Website auszuwerten, um Reports über die Websiteaktivitäten für die Websitebetreiber zusammenzustellen und um weitere mit der Websitenutzung und der Internetnutzung verbundene Dienstleistungen zu erbringen. Auch wird Google diese Informationen gegebenenfalls an Dritte übertragen, sofern dies gesetzlich vorgeschrieben oder soweit Dritte diese Daten im Auftrag von Google verarbeiten. Google wird in keinem Fall Ihre IP-Adresse mit anderen Daten der Google in Verbindung bringen. Sie können die Installation der Cookies durch eine entsprechende Einstellung Ihrer Browser Software verhindern; wir weisen Sie jedoch darauf hin, dass Sie in diesem Fall gegebenenfalls nicht sämtliche Funktionen dieser Website voll umfänglich nutzen können. Durch die Nutzung dieser Website erklären Sie sich mit der Bearbeitung der über Sie erhobenen Daten durch Google in der zuvor beschriebenen Art und Weise und zu dem zuvor benannten Zweck einverstanden.\nGoogle AdSense Diese Website benutzt Google Adsense, einen Webanzeigendienst der Google Inc., USA (‘’Google’‘). Google Adsense verwendet sog.’‘Cookies’’ (Textdateien), die auf Ihrem Computer gespeichert werden und die eine Analyse der Benutzung der Website durch Sie ermöglicht. Google Adsense verwendet auch sog. ‘’Web Beacons’’ (kleine unsichtbare Grafiken) zur Sammlung von Informationen. Durch die Verwendung des Web Beacons können einfache Aktionen wie der Besucherverkehr auf der Webseite aufgezeichnet und gesammelt werden. Die durch den Cookie und/oder Web Beacon erzeugten Informationen über Ihre Benutzung dieser Website (einschließlich Ihrer IP-Adresse) werden an einen Server von Google in den USA übertragen und dort gespeichert. Google wird diese Informationen benutzen, um Ihre Nutzung der Website im Hinblick auf die Anzeigen auszuwerten, um Reports über die Websiteaktivitäten und Anzeigen für die Websitebetreiber zusammenzustellen und um weitere mit der Websitenutzung und der Internetnutzung verbundene Dienstleistungen zu erbringen. Auch wird Google diese Informationen gegebenenfalls an Dritte übertragen, sofern dies gesetzlich vorgeschrieben oder soweit Dritte diese Daten im Auftrag von Google verarbeiten. Google wird in keinem Fall Ihre IP-Adresse mit anderen Daten der Google in Verbindung bringen. Das Speichern von Cookies auf Ihrer Festplatte und die Anzeige von Web Beacons können Sie verhindern, indem Sie in Ihren Browser-Einstellungen ‘’keine Cookies akzeptieren’’ wählen (Im MS Internet-Explorer unter ‘’Extras &gt; Internetoptionen &gt; Datenschutz &gt; Einstellung’‘; im Firefox unter’‘Extras &gt; Einstellungen &gt; Datenschutz &gt; Cookies’’); wir weisen Sie jedoch darauf hin, dass Sie in diesem Fall gegebenenfalls nicht sämtliche Funktionen dieser Website voll umfänglich nutzen können. Durch die Nutzung dieser Website erklären Sie sich mit der Bearbeitung der über Sie erhobenen Daten durch Google in der zuvor beschriebenen Art und Weise und zu dem zuvor benannten Zweck einverstanden.\nDiese Webseite nutzt Affiliate Links über das Amazon Partnerprogramm.\n\nDatenschutz­erklärung\n\n\n\nDatenschutz auf einen Blick\n\n\nAllgemeine Hinweise\n\n\nDie folgenden Hinweise geben einen einfachen Überblick darüber, was mit Ihren personenbezogenen Daten passiert, wenn Sie diese Website besuchen. Personenbezogene Daten sind alle Daten, mit denen Sie persönlich identifiziert werden können. Ausführliche Informationen zum Thema Datenschutz entnehmen Sie unserer unter diesem Text aufgeführten Datenschutzerklärung.\n\n\nDatenerfassung auf dieser Website\n\n\nWer ist verantwortlich für die Datenerfassung auf dieser Website?\n\n\nDie Datenverarbeitung auf dieser Website erfolgt durch den Websitebetreiber. Dessen Kontaktdaten können Sie dem Abschnitt „Hinweis zur Verantwortlichen Stelle“ in dieser Datenschutzerklärung entnehmen.\n\n\nWie erfassen wir Ihre Daten?\n\n\nIhre Daten werden zum einen dadurch erhoben, dass Sie uns diese mitteilen. Hierbei kann es sich z. B. um Daten handeln, die Sie in ein Kontaktformular eingeben.\n\n\nAndere Daten werden automatisch oder nach Ihrer Einwilligung beim Besuch der Website durch unsere IT-Systeme erfasst. Das sind vor allem technische Daten (z. B. Internetbrowser, Betriebssystem oder Uhrzeit des Seitenaufrufs). Die Erfassung dieser Daten erfolgt automatisch, sobald Sie diese Website betreten.\n\n\nWofür nutzen wir Ihre Daten?\n\n\nEin Teil der Daten wird erhoben, um eine fehlerfreie Bereitstellung der Website zu gewährleisten. Andere Daten können zur Analyse Ihres Nutzerverhaltens verwendet werden.\n\n\nWelche Rechte haben Sie bezüglich Ihrer Daten?\n\n\nSie haben jederzeit das Recht, unentgeltlich Auskunft über Herkunft, Empfänger und Zweck Ihrer gespeicherten personenbezogenen Daten zu erhalten. Sie haben außerdem ein Recht, die Berichtigung oder Löschung dieser Daten zu verlangen. Wenn Sie eine Einwilligung zur Datenverarbeitung erteilt haben, können Sie diese Einwilligung jederzeit für die Zukunft widerrufen. Außerdem haben Sie das Recht, unter bestimmten Umständen die Einschränkung der Verarbeitung Ihrer personenbezogenen Daten zu verlangen. Des Weiteren steht Ihnen ein Beschwerderecht bei der zuständigen Aufsichtsbehörde zu.\n\n\nHierzu sowie zu weiteren Fragen zum Thema Datenschutz können Sie sich jederzeit an uns wenden.\n\n\nAnalyse-Tools und Tools von Dritt­anbietern\n\n\nBeim Besuch dieser Website kann Ihr Surf-Verhalten statistisch ausgewertet werden. Das geschieht vor allem mit sogenannten Analyseprogrammen.\n\n\nDetaillierte Informationen zu diesen Analyseprogrammen finden Sie in der folgenden Datenschutzerklärung.\n\n\n\nHosting\n\n\nWir hosten die Inhalte unserer Website bei folgendem Anbieter:\n\n\nExternes Hosting\n\n\nDiese Website wird extern gehostet. Die personenbezogenen Daten, die auf dieser Website erfasst werden, werden auf den Servern des Hosters / der Hoster gespeichert. Hierbei kann es sich v. a. um IP-Adressen, Kontaktanfragen, Meta- und Kommunikationsdaten, Vertragsdaten, Kontaktdaten, Namen, Websitezugriffe und sonstige Daten, die über eine Website generiert werden, handeln.\n\n\nDas externe Hosting erfolgt zum Zwecke der Vertragserfüllung gegenüber unseren potenziellen und bestehenden Kunden (Art. 6 Abs. 1 lit. b DSGVO) und im Interesse einer sicheren, schnellen und effizienten Bereitstellung unseres Online-Angebots durch einen professionellen Anbieter (Art. 6 Abs. 1 lit. f DSGVO). Sofern eine entsprechende Einwilligung abgefragt wurde, erfolgt die Verarbeitung ausschließlich auf Grundlage von Art. 6 Abs. 1 lit. a DSGVO und § 25 Abs. 1 TTDSG, soweit die Einwilligung die Speicherung von Cookies oder den Zugriff auf Informationen im Endgerät des Nutzers (z. B. Device-Fingerprinting) im Sinne des TTDSG umfasst. Die Einwilligung ist jederzeit widerrufbar.\n\n\nUnser(e) Hoster wird bzw. werden Ihre Daten nur insoweit verarbeiten, wie dies zur Erfüllung seiner Leistungspflichten erforderlich ist und unsere Weisungen in Bezug auf diese Daten befolgen.\n\n\nWir setzen folgende(n) Hoster ein:\n\n\nNetlify\n\n\n\nAllgemeine Hinweise und Pflicht­informationen\n\n\nDatenschutz\n\n\nDie Betreiber dieser Seiten nehmen den Schutz Ihrer persönlichen Daten sehr ernst. Wir behandeln Ihre personenbezogenen Daten vertraulich und entsprechend den gesetzlichen Datenschutzvorschriften sowie dieser Datenschutzerklärung.\n\n\nWenn Sie diese Website benutzen, werden verschiedene personenbezogene Daten erhoben. Personenbezogene Daten sind Daten, mit denen Sie persönlich identifiziert werden können. Die vorliegende Datenschutzerklärung erläutert, welche Daten wir erheben und wofür wir sie nutzen. Sie erläutert auch, wie und zu welchem Zweck das geschieht.\n\n\nWir weisen darauf hin, dass die Datenübertragung im Internet (z. B. bei der Kommunikation per E-Mail) Sicherheitslücken aufweisen kann. Ein lückenloser Schutz der Daten vor dem Zugriff durch Dritte ist nicht möglich.\n\n\nHinweis zur verantwortlichen Stelle\n\n\nDie verantwortliche Stelle für die Datenverarbeitung auf dieser Website ist:\n\n\n[Voller Namen bzw. die vollständige Unternehmensbezeichnung des Website-Betreibers sowie die vollständige Anschrift]\n\n\nTelefon: [Telefonnummer der verantwortlichen Stelle] E-Mail: paul //dot__ buerkner __at// gmail _dot/ com\n\n\nVerantwortliche Stelle ist die natürliche oder juristische Person, die allein oder gemeinsam mit anderen über die Zwecke und Mittel der Verarbeitung von personenbezogenen Daten (z. B. Namen, E-Mail-Adressen o. Ä.) entscheidet.\n\n\n\n\n\nSpeicherdauer\n\n\nSoweit innerhalb dieser Datenschutzerklärung keine speziellere Speicherdauer genannt wurde, verbleiben Ihre personenbezogenen Daten bei uns, bis der Zweck für die Datenverarbeitung entfällt. Wenn Sie ein berechtigtes Löschersuchen geltend machen oder eine Einwilligung zur Datenverarbeitung widerrufen, werden Ihre Daten gelöscht, sofern wir keine anderen rechtlich zulässigen Gründe für die Speicherung Ihrer personenbezogenen Daten haben (z. B. steuer- oder handelsrechtliche Aufbewahrungsfristen); im letztgenannten Fall erfolgt die Löschung nach Fortfall dieser Gründe.\n\n\nAllgemeine Hinweise zu den Rechtsgrundlagen der Datenverarbeitung auf dieser Website\n\n\nSofern Sie in die Datenverarbeitung eingewilligt haben, verarbeiten wir Ihre personenbezogenen Daten auf Grundlage von Art. 6 Abs. 1 lit. a DSGVO bzw. Art. 9 Abs. 2 lit. a DSGVO, sofern besondere Datenkategorien nach Art. 9 Abs. 1 DSGVO verarbeitet werden. Im Falle einer ausdrücklichen Einwilligung in die Übertragung personenbezogener Daten in Drittstaaten erfolgt die Datenverarbeitung außerdem auf Grundlage von Art. 49 Abs. 1 lit. a DSGVO. Sofern Sie in die Speicherung von Cookies oder in den Zugriff auf Informationen in Ihr Endgerät (z. B. via Device-Fingerprinting) eingewilligt haben, erfolgt die Datenverarbeitung zusätzlich auf Grundlage von § 25 Abs. 1 TTDSG. Die Einwilligung ist jederzeit widerrufbar. Sind Ihre Daten zur Vertragserfüllung oder zur Durchführung vorvertraglicher Maßnahmen erforderlich, verarbeiten wir Ihre Daten auf Grundlage des Art. 6 Abs. 1 lit. b DSGVO. Des Weiteren verarbeiten wir Ihre Daten, sofern diese zur Erfüllung einer rechtlichen Verpflichtung erforderlich sind auf Grundlage von Art. 6 Abs. 1 lit. c DSGVO. Die Datenverarbeitung kann ferner auf Grundlage unseres berechtigten Interesses nach Art. 6 Abs. 1 lit. f DSGVO erfolgen. Über die jeweils im Einzelfall einschlägigen Rechtsgrundlagen wird in den folgenden Absätzen dieser Datenschutzerklärung informiert.\n\n\nHinweis zur Datenweitergabe in die USA und sonstige Drittstaaten\n\n\nWir verwenden unter anderem Tools von Unternehmen mit Sitz in den USA oder sonstigen datenschutzrechtlich nicht sicheren Drittstaaten. Wenn diese Tools aktiv sind, können Ihre personenbezogene Daten in diese Drittstaaten übertragen und dort verarbeitet werden. Wir weisen darauf hin, dass in diesen Ländern kein mit der EU vergleichbares Datenschutzniveau garantiert werden kann. Beispielsweise sind US-Unternehmen dazu verpflichtet, personenbezogene Daten an Sicherheitsbehörden herauszugeben, ohne dass Sie als Betroffener hiergegen gerichtlich vorgehen könnten. Es kann daher nicht ausgeschlossen werden, dass US-Behörden (z. B. Geheimdienste) Ihre auf US-Servern befindlichen Daten zu Überwachungszwecken verarbeiten, auswerten und dauerhaft speichern. Wir haben auf diese Verarbeitungstätigkeiten keinen Einfluss.\n\n\nWiderruf Ihrer Einwilligung zur Datenverarbeitung\n\n\nViele Datenverarbeitungsvorgänge sind nur mit Ihrer ausdrücklichen Einwilligung möglich. Sie können eine bereits erteilte Einwilligung jederzeit widerrufen. Die Rechtmäßigkeit der bis zum Widerruf erfolgten Datenverarbeitung bleibt vom Widerruf unberührt.\n\n\nWiderspruchsrecht gegen die Datenerhebung in besonderen Fällen sowie gegen Direktwerbung (Art. 21 DSGVO)\n\n\nWENN DIE DATENVERARBEITUNG AUF GRUNDLAGE VON ART. 6 ABS. 1 LIT. E ODER F DSGVO ERFOLGT, HABEN SIE JEDERZEIT DAS RECHT, AUS GRÜNDEN, DIE SICH AUS IHRER BESONDEREN SITUATION ERGEBEN, GEGEN DIE VERARBEITUNG IHRER PERSONENBEZOGENEN DATEN WIDERSPRUCH EINZULEGEN; DIES GILT AUCH FÜR EIN AUF DIESE BESTIMMUNGEN GESTÜTZTES PROFILING. DIE JEWEILIGE RECHTSGRUNDLAGE, AUF DENEN EINE VERARBEITUNG BERUHT, ENTNEHMEN SIE DIESER DATENSCHUTZERKLÄRUNG. WENN SIE WIDERSPRUCH EINLEGEN, WERDEN WIR IHRE BETROFFENEN PERSONENBEZOGENEN DATEN NICHT MEHR VERARBEITEN, ES SEI DENN, WIR KÖNNEN ZWINGENDE SCHUTZWÜRDIGE GRÜNDE FÜR DIE VERARBEITUNG NACHWEISEN, DIE IHRE INTERESSEN, RECHTE UND FREIHEITEN ÜBERWIEGEN ODER DIE VERARBEITUNG DIENT DER GELTENDMACHUNG, AUSÜBUNG ODER VERTEIDIGUNG VON RECHTSANSPRÜCHEN (WIDERSPRUCH NACH ART. 21 ABS. 1 DSGVO).\n\n\nWERDEN IHRE PERSONENBEZOGENEN DATEN VERARBEITET, UM DIREKTWERBUNG ZU BETREIBEN, SO HABEN SIE DAS RECHT, JEDERZEIT WIDERSPRUCH GEGEN DIE VERARBEITUNG SIE BETREFFENDER PERSONENBEZOGENER DATEN ZUM ZWECKE DERARTIGER WERBUNG EINZULEGEN; DIES GILT AUCH FÜR DAS PROFILING, SOWEIT ES MIT SOLCHER DIREKTWERBUNG IN VERBINDUNG STEHT. WENN SIE WIDERSPRECHEN, WERDEN IHRE PERSONENBEZOGENEN DATEN ANSCHLIESSEND NICHT MEHR ZUM ZWECKE DER DIREKTWERBUNG VERWENDET (WIDERSPRUCH NACH ART. 21 ABS. 2 DSGVO).\n\n\nBeschwerde­recht bei der zuständigen Aufsichts­behörde\n\n\nIm Falle von Verstößen gegen die DSGVO steht den Betroffenen ein Beschwerderecht bei einer Aufsichtsbehörde, insbesondere in dem Mitgliedstaat ihres gewöhnlichen Aufenthalts, ihres Arbeitsplatzes oder des Orts des mutmaßlichen Verstoßes zu. Das Beschwerderecht besteht unbeschadet anderweitiger verwaltungsrechtlicher oder gerichtlicher Rechtsbehelfe.\n\n\nRecht auf Daten­übertrag­barkeit\n\n\nSie haben das Recht, Daten, die wir auf Grundlage Ihrer Einwilligung oder in Erfüllung eines Vertrags automatisiert verarbeiten, an sich oder an einen Dritten in einem gängigen, maschinenlesbaren Format aushändigen zu lassen. Sofern Sie die direkte Übertragung der Daten an einen anderen Verantwortlichen verlangen, erfolgt dies nur, soweit es technisch machbar ist.\n\n\nAuskunft, Löschung und Berichtigung\n\n\nSie haben im Rahmen der geltenden gesetzlichen Bestimmungen jederzeit das Recht auf unentgeltliche Auskunft über Ihre gespeicherten personenbezogenen Daten, deren Herkunft und Empfänger und den Zweck der Datenverarbeitung und ggf. ein Recht auf Berichtigung oder Löschung dieser Daten. Hierzu sowie zu weiteren Fragen zum Thema personenbezogene Daten können Sie sich jederzeit an uns wenden.\n\n\nRecht auf Einschränkung der Verarbeitung\n\n\nSie haben das Recht, die Einschränkung der Verarbeitung Ihrer personenbezogenen Daten zu verlangen. Hierzu können Sie sich jederzeit an uns wenden. Das Recht auf Einschränkung der Verarbeitung besteht in folgenden Fällen:\n\n\n\nWenn Sie die Richtigkeit Ihrer bei uns gespeicherten personenbezogenen Daten bestreiten, benötigen wir in der Regel Zeit, um dies zu überprüfen. Für die Dauer der Prüfung haben Sie das Recht, die Einschränkung der Verarbeitung Ihrer personenbezogenen Daten zu verlangen.\n\n\nWenn die Verarbeitung Ihrer personenbezogenen Daten unrechtmäßig geschah/geschieht, können Sie statt der Löschung die Einschränkung der Datenverarbeitung verlangen.\n\n\nWenn wir Ihre personenbezogenen Daten nicht mehr benötigen, Sie sie jedoch zur Ausübung, Verteidigung oder Geltendmachung von Rechtsansprüchen benötigen, haben Sie das Recht, statt der Löschung die Einschränkung der Verarbeitung Ihrer personenbezogenen Daten zu verlangen.\n\n\nWenn Sie einen Widerspruch nach Art. 21 Abs. 1 DSGVO eingelegt haben, muss eine Abwägung zwischen Ihren und unseren Interessen vorgenommen werden. Solange noch nicht feststeht, wessen Interessen überwiegen, haben Sie das Recht, die Einschränkung der Verarbeitung Ihrer personenbezogenen Daten zu verlangen.\n\n\n\nWenn Sie die Verarbeitung Ihrer personenbezogenen Daten eingeschränkt haben, dürfen diese Daten – von ihrer Speicherung abgesehen – nur mit Ihrer Einwilligung oder zur Geltendmachung, Ausübung oder Verteidigung von Rechtsansprüchen oder zum Schutz der Rechte einer anderen natürlichen oder juristischen Person oder aus Gründen eines wichtigen öffentlichen Interesses der Europäischen Union oder eines Mitgliedstaats verarbeitet werden.\n\n\nSSL- bzw. TLS-Verschlüsselung\n\n\nDiese Seite nutzt aus Sicherheitsgründen und zum Schutz der Übertragung vertraulicher Inhalte, wie zum Beispiel Bestellungen oder Anfragen, die Sie an uns als Seitenbetreiber senden, eine SSL- bzw. TLS-Verschlüsselung. Eine verschlüsselte Verbindung erkennen Sie daran, dass die Adresszeile des Browsers von „http://“ auf „https://“ wechselt und an dem Schloss-Symbol in Ihrer Browserzeile.\n\n\nWenn die SSL- bzw. TLS-Verschlüsselung aktiviert ist, können die Daten, die Sie an uns übermitteln, nicht von Dritten mitgelesen werden.\n\n\n\nDatenerfassung auf dieser Website\n\n\nCookies\n\n\nUnsere Internetseiten verwenden so genannte „Cookies“. Cookies sind kleine Datenpakete und richten auf Ihrem Endgerät keinen Schaden an. Sie werden entweder vorübergehend für die Dauer einer Sitzung (Session-Cookies) oder dauerhaft (permanente Cookies) auf Ihrem Endgerät gespeichert. Session-Cookies werden nach Ende Ihres Besuchs automatisch gelöscht. Permanente Cookies bleiben auf Ihrem Endgerät gespeichert, bis Sie diese selbst löschen oder eine automatische Löschung durch Ihren Webbrowser erfolgt.\n\n\nCookies können von uns (First-Party-Cookies) oder von Drittunternehmen stammen (sog. Third-Party-Cookies). Third-Party-Cookies ermöglichen die Einbindung bestimmter Dienstleistungen von Drittunternehmen innerhalb von Webseiten (z. B. Cookies zur Abwicklung von Zahlungsdienstleistungen).\n\n\nCookies haben verschiedene Funktionen. Zahlreiche Cookies sind technisch notwendig, da bestimmte Webseitenfunktionen ohne diese nicht funktionieren würden (z. B. die Warenkorbfunktion oder die Anzeige von Videos). Andere Cookies können zur Auswertung des Nutzerverhaltens oder zu Werbezwecken verwendet werden.\n\n\nCookies, die zur Durchführung des elektronischen Kommunikationsvorgangs, zur Bereitstellung bestimmter, von Ihnen erwünschter Funktionen (z. B. für die Warenkorbfunktion) oder zur Optimierung der Website (z. B. Cookies zur Messung des Webpublikums) erforderlich sind (notwendige Cookies), werden auf Grundlage von Art. 6 Abs. 1 lit. f DSGVO gespeichert, sofern keine andere Rechtsgrundlage angegeben wird. Der Websitebetreiber hat ein berechtigtes Interesse an der Speicherung von notwendigen Cookies zur technisch fehlerfreien und optimierten Bereitstellung seiner Dienste. Sofern eine Einwilligung zur Speicherung von Cookies und vergleichbaren Wiedererkennungstechnologien abgefragt wurde, erfolgt die Verarbeitung ausschließlich auf Grundlage dieser Einwilligung (Art. 6 Abs. 1 lit. a DSGVO und § 25 Abs. 1 TTDSG); die Einwilligung ist jederzeit widerrufbar.\n\n\nSie können Ihren Browser so einstellen, dass Sie über das Setzen von Cookies informiert werden und Cookies nur im Einzelfall erlauben, die Annahme von Cookies für bestimmte Fälle oder generell ausschließen sowie das automatische Löschen der Cookies beim Schließen des Browsers aktivieren. Bei der Deaktivierung von Cookies kann die Funktionalität dieser Website eingeschränkt sein.\n\n\nWelche Cookies und Dienste auf dieser Website eingesetzt werden, können Sie dieser Datenschutzerklärung entnehmen.\n\n\nKontaktformular\n\n\nWenn Sie uns per Kontaktformular Anfragen zukommen lassen, werden Ihre Angaben aus dem Anfrageformular inklusive der von Ihnen dort angegebenen Kontaktdaten zwecks Bearbeitung der Anfrage und für den Fall von Anschlussfragen bei uns gespeichert. Diese Daten geben wir nicht ohne Ihre Einwilligung weiter.\n\n\nDie Verarbeitung dieser Daten erfolgt auf Grundlage von Art. 6 Abs. 1 lit. b DSGVO, sofern Ihre Anfrage mit der Erfüllung eines Vertrags zusammenhängt oder zur Durchführung vorvertraglicher Maßnahmen erforderlich ist. In allen übrigen Fällen beruht die Verarbeitung auf unserem berechtigten Interesse an der effektiven Bearbeitung der an uns gerichteten Anfragen (Art. 6 Abs. 1 lit. f DSGVO) oder auf Ihrer Einwilligung (Art. 6 Abs. 1 lit. a DSGVO) sofern diese abgefragt wurde; die Einwilligung ist jederzeit widerrufbar.\n\n\nDie von Ihnen im Kontaktformular eingegebenen Daten verbleiben bei uns, bis Sie uns zur Löschung auffordern, Ihre Einwilligung zur Speicherung widerrufen oder der Zweck für die Datenspeicherung entfällt (z. B. nach abgeschlossener Bearbeitung Ihrer Anfrage). Zwingende gesetzliche Bestimmungen – insbesondere Aufbewahrungsfristen – bleiben unberührt.\n\n\n\nSoziale Medien\n\n\nFacebook\n\n\nAuf dieser Website sind Elemente des sozialen Netzwerks Facebook integriert. Anbieter dieses Dienstes ist die Meta Platforms Ireland Limited, 4 Grand Canal Square, Dublin 2, Irland. Die erfassten Daten werden nach Aussage von Facebook jedoch auch in die USA und in andere Drittländer übertragen.\n\n\nEine Übersicht über die Facebook Social-Media-Elemente finden Sie hier: https://developers.facebook.com/docs/plugins/?locale=de_DE.\n\n\nWenn das Social-Media-Element aktiv ist, wird eine direkte Verbindung zwischen Ihrem Endgerät und dem Facebook-Server hergestellt. Facebook erhält dadurch die Information, dass Sie mit Ihrer IP-Adresse diese Website besucht haben. Wenn Sie den Facebook „Like-Button“ anklicken, während Sie in Ihrem Facebook-Account eingeloggt sind, können Sie die Inhalte dieser Website auf Ihrem Facebook-Profil verlinken. Dadurch kann Facebook den Besuch dieser Website Ihrem Benutzerkonto zuordnen. Wir weisen darauf hin, dass wir als Anbieter der Seiten keine Kenntnis vom Inhalt der übermittelten Daten sowie deren Nutzung durch Facebook erhalten. Weitere Informationen hierzu finden Sie in der Datenschutzerklärung von Facebook unter: https://de-de.facebook.com/privacy/explanation.\n\n\nSoweit eine Einwilligung (Consent) eingeholt wurde, erfolgt der Einsatz des o. g. Dienstes auf Grundlage von Art. 6 Abs. 1 lit. a DSGVO und § 25 TTDSG. Die Einwilligung ist jederzeit widerrufbar. Soweit keine Einwilligung eingeholt wurde, erfolgt die Verwendung des Dienstes auf Grundlage unseres berechtigten Interesses an einer möglichst umfassenden Sichtbarkeit in den Sozialen Medien.\n\n\nSoweit mit Hilfe des hier beschriebenen Tools personenbezogene Daten auf unserer Website erfasst und an Facebook weitergeleitet werden, sind wir und die Meta Platforms Ireland Limited, 4 Grand Canal Square, Grand Canal Harbour, Dublin 2, Irland gemeinsam für diese Datenverarbeitung verantwortlich (Art. 26 DSGVO). Die gemeinsame Verantwortlichkeit beschränkt sich dabei ausschließlich auf die Erfassung der Daten und deren Weitergabe an Facebook. Die nach der Weiterleitung erfolgende Verarbeitung durch Facebook ist nicht Teil der gemeinsamen Verantwortung. Die uns gemeinsam obliegenden Verpflichtungen wurden in einer Vereinbarung über gemeinsame Verarbeitung festgehalten. Den Wortlaut der Vereinbarung finden Sie unter: https://www.facebook.com/legal/controller_addendum. Laut dieser Vereinbarung sind wir für die Erteilung der Datenschutzinformationen beim Einsatz des Facebook-Tools und für die datenschutzrechtlich sichere Implementierung des Tools auf unserer Website verantwortlich. Für die Datensicherheit der Facebook-Produkte ist Facebook verantwortlich. Betroffenenrechte (z. B. Auskunftsersuchen) hinsichtlich der bei Facebook verarbeiteten Daten können Sie direkt bei Facebook geltend machen. Wenn Sie die Betroffenenrechte bei uns geltend machen, sind wir verpflichtet, diese an Facebook weiterzuleiten.\n\n\nDie Datenübertragung in die USA wird auf die Standardvertragsklauseln der EU-Kommission gestützt. Details finden Sie hier: https://www.facebook.com/legal/EU_data_transfer_addendum, https://de-de.facebook.com/help/566994660333381 und https://www.facebook.com/policy.php.\n\n\nTwitter\n\n\nAuf dieser Website sind Funktionen des Dienstes Twitter eingebunden. Diese Funktionen werden angeboten durch die Twitter International Company, One Cumberland Place, Fenian Street, Dublin 2, D02 AX07, Irland.\n\n\nWenn das Social-Media-Element aktiv ist, wird eine direkte Verbindung zwischen Ihrem Endgerät und dem Twitter-Server hergestellt. Twitter erhält dadurch Informationen über den Besuch dieser Website durch Sie. Durch das Benutzen von Twitter und der Funktion „Re-Tweet“ werden die von Ihnen besuchten Websites mit Ihrem Twitter-Account verknüpft und anderen Nutzern bekannt gegeben. Wir weisen darauf hin, dass wir als Anbieter der Seiten keine Kenntnis vom Inhalt der übermittelten Daten sowie deren Nutzung durch Twitter erhalten. Weitere Informationen hierzu finden Sie in der Datenschutzerklärung von Twitter unter: https://twitter.com/de/privacy.\n\n\nSoweit eine Einwilligung (Consent) eingeholt wurde, erfolgt der Einsatz des o. g. Dienstes auf Grundlage von Art. 6 Abs. 1 lit. a DSGVO und § 25 TTDSG. Die Einwilligung ist jederzeit widerrufbar. Soweit keine Einwilligung eingeholt wurde, erfolgt die Verwendung des Dienstes auf Grundlage unseres berechtigten Interesses an einer möglichst umfassenden Sichtbarkeit in den Sozialen Medien.\n\n\nDie Datenübertragung in die USA wird auf die Standardvertragsklauseln der EU-Kommission gestützt. Details finden Sie hier: https://gdpr.twitter.com/en/controller-to-controller-transfers.html.\n\n\nIhre Datenschutzeinstellungen bei Twitter können Sie in den Konto-Einstellungen unter https://twitter.com/account/settings ändern.\n\n\n\nNewsletter\n\n\nNewsletter­daten\n\n\nWenn Sie den auf der Website angebotenen Newsletter beziehen möchten, benötigen wir von Ihnen eine E-Mail-Adresse sowie Informationen, welche uns die Überprüfung gestatten, dass Sie der Inhaber der angegebenen E-Mail-Adresse sind und mit dem Empfang des Newsletters einverstanden sind. Weitere Daten werden nicht bzw. nur auf freiwilliger Basis erhoben. Diese Daten verwenden wir ausschließlich für den Versand der angeforderten Informationen und geben diese nicht an Dritte weiter.\n\n\nDie Verarbeitung der in das Newsletteranmeldeformular eingegebenen Daten erfolgt ausschließlich auf Grundlage Ihrer Einwilligung (Art. 6 Abs. 1 lit. a DSGVO). Die erteilte Einwilligung zur Speicherung der Daten, der E-Mail-Adresse sowie deren Nutzung zum Versand des Newsletters können Sie jederzeit widerrufen, etwa über den „Austragen“-Link im Newsletter. Die Rechtmäßigkeit der bereits erfolgten Datenverarbeitungsvorgänge bleibt vom Widerruf unberührt.\n\n\nDie von Ihnen zum Zwecke des Newsletter-Bezugs bei uns hinterlegten Daten werden von uns bis zu Ihrer Austragung aus dem Newsletter bei uns bzw. dem Newsletterdiensteanbieter gespeichert und nach der Abbestellung des Newsletters oder nach Zweckfortfall aus der Newsletterverteilerliste gelöscht. Wir behalten uns vor, E-Mail-Adressen aus unserem Newsletterverteiler nach eigenem Ermessen im Rahmen unseres berechtigten Interesses nach Art. 6 Abs. 1 lit. f DSGVO zu löschen oder zu sperren.\n\n\nDaten, die zu anderen Zwecken bei uns gespeichert wurden, bleiben hiervon unberührt.\n\n\nNach Ihrer Austragung aus der Newsletterverteilerliste wird Ihre E-Mail-Adresse bei uns bzw. dem Newsletterdiensteanbieter ggf. in einer Blacklist gespeichert, sofern dies zur Verhinderung künftiger Mailings erforderlich ist. Die Daten aus der Blacklist werden nur für diesen Zweck verwendet und nicht mit anderen Daten zusammengeführt. Dies dient sowohl Ihrem Interesse als auch unserem Interesse an der Einhaltung der gesetzlichen Vorgaben beim Versand von Newslettern (berechtigtes Interesse im Sinne des Art. 6 Abs. 1 lit. f DSGVO). Die Speicherung in der Blacklist ist zeitlich nicht befristet. Sie können der Speicherung widersprechen, sofern Ihre Interessen unser berechtigtes Interesse überwiegen.\n\n\n\nPlugins und Tools\n\n\nYouTube mit erweitertem Datenschutz\n\n\nDiese Website bindet Videos der Website YouTube ein. Betreiber der Seiten ist die Google Ireland Limited („Google“), Gordon House, Barrow Street, Dublin 4, Irland.\n\n\nWir nutzen YouTube im erweiterten Datenschutzmodus. Dieser Modus bewirkt laut YouTube, dass YouTube keine Informationen über die Besucher auf dieser Website speichert, bevor diese sich das Video ansehen. Die Weitergabe von Daten an YouTube-Partner wird durch den erweiterten Datenschutzmodus hingegen nicht zwingend ausgeschlossen. So stellt YouTube – unabhängig davon, ob Sie sich ein Video ansehen – eine Verbindung zum Google DoubleClick-Netzwerk her.\n\n\nSobald Sie ein YouTube-Video auf dieser Website starten, wird eine Verbindung zu den Servern von YouTube hergestellt. Dabei wird dem YouTube-Server mitgeteilt, welche unserer Seiten Sie besucht haben. Wenn Sie in Ihrem YouTube-Account eingeloggt sind, ermöglichen Sie YouTube, Ihr Surfverhalten direkt Ihrem persönlichen Profil zuzuordnen. Dies können Sie verhindern, indem Sie sich aus Ihrem YouTube-Account ausloggen.\n\n\nDes Weiteren kann YouTube nach Starten eines Videos verschiedene Cookies auf Ihrem Endgerät speichern oder vergleichbare Wiedererkennungstechnologien (z. B. Device-Fingerprinting) einsetzen. Auf diese Weise kann YouTube Informationen über Besucher dieser Website erhalten. Diese Informationen werden u. a. verwendet, um Videostatistiken zu erfassen, die Anwenderfreundlichkeit zu verbessern und Betrugsversuchen vorzubeugen.\n\n\nGegebenenfalls können nach dem Start eines YouTube-Videos weitere Datenverarbeitungsvorgänge ausgelöst werden, auf die wir keinen Einfluss haben.\n\n\nDie Nutzung von YouTube erfolgt im Interesse einer ansprechenden Darstellung unserer Online-Angebote. Dies stellt ein berechtigtes Interesse im Sinne von Art. 6 Abs. 1 lit. f DSGVO dar. Sofern eine entsprechende Einwilligung abgefragt wurde, erfolgt die Verarbeitung ausschließlich auf Grundlage von Art. 6 Abs. 1 lit. a DSGVO und § 25 Abs. 1 TTDSG, soweit die Einwilligung die Speicherung von Cookies oder den Zugriff auf Informationen im Endgerät des Nutzers (z. B. Device-Fingerprinting) im Sinne des TTDSG umfasst. Die Einwilligung ist jederzeit widerrufbar.\n\n\nWeitere Informationen über Datenschutz bei YouTube finden Sie in deren Datenschutzerklärung unter: https://policies.google.com/privacy?hl=de.\n\n\nGoogle Fonts (lokales Hosting)\n\n\nDiese Seite nutzt zur einheitlichen Darstellung von Schriftarten so genannte Google Fonts, die von Google bereitgestellt werden. Die Google Fonts sind lokal installiert. Eine Verbindung zu Servern von Google findet dabei nicht statt.\n\n\nWeitere Informationen zu Google Fonts finden Sie unter https://developers.google.com/fonts/faq und in der Datenschutzerklärung von Google: https://policies.google.com/privacy?hl=de.\n\n\nFont Awesome (lokales Hosting)\n\n\nDiese Seite nutzt zur einheitlichen Darstellung von Schriftarten Font Awesome. Font Awesome ist lokal installiert. Eine Verbindung zu Servern von Fonticons, Inc. findet dabei nicht statt.\n\n\nWeitere Informationen zu Font Awesome finden Sie in der Datenschutzerklärung für Font Awesome unter: https://fontawesome.com/privacy.\n\n\nGoogle Maps\n\n\nDiese Seite nutzt den Kartendienst Google Maps. Anbieter ist die Google Ireland Limited („Google“), Gordon House, Barrow Street, Dublin 4, Irland.\n\n\nZur Nutzung der Funktionen von Google Maps ist es notwendig, Ihre IP-Adresse zu speichern. Diese Informationen werden in der Regel an einen Server von Google in den USA übertragen und dort gespeichert. Der Anbieter dieser Seite hat keinen Einfluss auf diese Datenübertragung. Wenn Google Maps aktiviert ist, kann Google zum Zwecke der einheitlichen Darstellung der Schriftarten Google Fonts verwenden. Beim Aufruf von Google Maps lädt Ihr Browser die benötigten Web Fonts in ihren Browsercache, um Texte und Schriftarten korrekt anzuzeigen.\n\n\nDie Nutzung von Google Maps erfolgt im Interesse einer ansprechenden Darstellung unserer Online-Angebote und an einer leichten Auffindbarkeit der von uns auf der Website angegebenen Orte. Dies stellt ein berechtigtes Interesse im Sinne von Art. 6 Abs. 1 lit. f DSGVO dar. Sofern eine entsprechende Einwilligung abgefragt wurde, erfolgt die Verarbeitung ausschließlich auf Grundlage von Art. 6 Abs. 1 lit. a DSGVO und § 25 Abs. 1 TTDSG, soweit die Einwilligung die Speicherung von Cookies oder den Zugriff auf Informationen im Endgerät des Nutzers (z. B. Device-Fingerprinting) im Sinne des TTDSG umfasst. Die Einwilligung ist jederzeit widerrufbar.\n\n\nDie Datenübertragung in die USA wird auf die Standardvertragsklauseln der EU-Kommission gestützt. Details finden Sie hier: https://privacy.google.com/businesses/gdprcontrollerterms/ und https://privacy.google.com/businesses/gdprcontrollerterms/sccs/.\n\n\nMehr Informationen zum Umgang mit Nutzerdaten finden Sie in der Datenschutzerklärung von Google: https://policies.google.com/privacy?hl=de.\n\n\nOpenStreetMap\n\n\nWir nutzen den Kartendienst von OpenStreetMap (OSM).\n\n\nWir binden das Kartenmaterial von OpenStreetMap auf dem Server der OpenStreetMap Foundation, St John’s Innovation Centre, Cowley Road, Cambridge, CB4 0WS, Großbritannien, ein. Großbritannien gilt als datenschutzrechtlich sicherer Drittstaat. Das bedeutet, dass Großbritannien ein Datenschutzniveau aufweist, das dem Datenschutzniveau in der Europäischen Union entspricht. Bei der Nutzung der OpenStreetMap-Karten wird eine Verbindung zu den Servern der OpenStreetMap-Foundation hergestellt. Dabei können u. a. Ihre IP-Adresse und weitere Informationen über Ihr Verhalten auf dieser Website an die OSMF weitergeleitet werden. OpenStreetMap speichert hierzu unter Umständen Cookies in Ihrem Browser oder setzt vergleichbare Wiedererkennungstechnologien ein.\n\n\nDie Nutzung von OpenStreetMap erfolgt im Interesse einer ansprechenden Darstellung unserer Online-Angebote und einer leichten Auffindbarkeit der von uns auf der Website angegebenen Orte. Dies stellt ein berechtigtes Interesse im Sinne von Art. 6 Abs. 1 lit. f DSGVO dar. Sofern eine entsprechende Einwilligung abgefragt wurde, erfolgt die Verarbeitung ausschließlich auf Grundlage von Art. 6 Abs. 1 lit. a DSGVO und § 25 Abs. 1 TTDSG, soweit die Einwilligung die Speicherung von Cookies oder den Zugriff auf Informationen im Endgerät des Nutzers (z. B. Device-Fingerprinting) im Sinne des TTDSG umfasst. Die Einwilligung ist jederzeit widerrufbar.\n\n\nGoogle reCAPTCHA\n\n\nWir nutzen „Google reCAPTCHA“ (im Folgenden „reCAPTCHA“) auf dieser Website. Anbieter ist die Google Ireland Limited („Google“), Gordon House, Barrow Street, Dublin 4, Irland.\n\n\nMit reCAPTCHA soll überprüft werden, ob die Dateneingabe auf dieser Website (z. B. in einem Kontaktformular) durch einen Menschen oder durch ein automatisiertes Programm erfolgt. Hierzu analysiert reCAPTCHA das Verhalten des Websitebesuchers anhand verschiedener Merkmale. Diese Analyse beginnt automatisch, sobald der Websitebesucher die Website betritt. Zur Analyse wertet reCAPTCHA verschiedene Informationen aus (z. B. IP-Adresse, Verweildauer des Websitebesuchers auf der Website oder vom Nutzer getätigte Mausbewegungen). Die bei der Analyse erfassten Daten werden an Google weitergeleitet.\n\n\nDie reCAPTCHA-Analysen laufen vollständig im Hintergrund. Websitebesucher werden nicht darauf hingewiesen, dass eine Analyse stattfindet.\n\n\nDie Speicherung und Analyse der Daten erfolgt auf Grundlage von Art. 6 Abs. 1 lit. f DSGVO. Der Websitebetreiber hat ein berechtigtes Interesse daran, seine Webangebote vor missbräuchlicher automatisierter Ausspähung und vor SPAM zu schützen. Sofern eine entsprechende Einwilligung abgefragt wurde, erfolgt die Verarbeitung ausschließlich auf Grundlage von Art. 6 Abs. 1 lit. a DSGVO und § 25 Abs. 1 TTDSG, soweit die Einwilligung die Speicherung von Cookies oder den Zugriff auf Informationen im Endgerät des Nutzers (z. B. Device-Fingerprinting) im Sinne des TTDSG umfasst. Die Einwilligung ist jederzeit widerrufbar.\n\n\nWeitere Informationen zu Google reCAPTCHA entnehmen Sie den Google-Datenschutzbestimmungen und den Google Nutzungsbedingungen unter folgenden Links: https://policies.google.com/privacy?hl=de und https://policies.google.com/terms?hl=de.\n\n\n\n\n\nImpressum vom Impressum Generator der Kanzlei Hasselbach, Rechtsanwälte für Arbeitsrecht und Familienrecht, sowie von https://www.e-recht24.de."
  },
  {
    "objectID": "positions/index.html",
    "href": "positions/index.html",
    "title": "Open Positions",
    "section": "",
    "text": "If you are interested in joining my lab at as a PhD student or PostDoc, please reach out to me at any point; even if there is currently no announced open position available that you think matches your profile. The same goes if you are a student looking for a student assistant position.\n\nThere are currently no officially announced open positions, but remember that you can just contact me at any point to ask for opportunities."
  },
  {
    "objectID": "projects/index.html#completed-projects",
    "href": "projects/index.html#completed-projects",
    "title": "Research Projects",
    "section": "Completed Projects",
    "text": "Completed Projects\n\n\n\n\n\n\nMachine Learning for Bayesian Model Building\n\n\n\n\n\n\n\n\n\n\nThe Bayesian approach to data analysis provides a consistent and flexible way to handle uncertainty in all observations, model parameters, and model structure using probability theory. However, building Bayesian models in a principled way remains a highly complex task requiring a lot of expertise and cognitive resources. In this project, we will develop a machine assisted workflow for building interpretable, robust, and well-predicting Bayesian models. Based on statistical theory, we will develop a framework for simulating realistic data with known modeling challenges. Subsequently, using neural network architectures tuned to the structure of the fitted Bayesian models, machines will be trained on the simulated data to provide automatic model evaluation and modeling recommendations that guide the user through the model building process using interactive visualizations. While leaving the modeling choices up to the user, the machine learns from the user’s decisions to improve its recommendations on the fly.\nOverarching Topics: Machine-Assisted Workflows Model Comparison Uncertainty Quantification\nProject Members: Maximilian Scholz\nFunders: Cluster of Excellence SimTech\nFunding Period: 2021 – 2024\nPublications:\n\nFazio L., Scholz M., & Bürkner P. C. (in review). Generative Bayesian Modeling with Implicit Priors. ArXiv preprint. Preprint Code & Data\nScholz M. & Bürkner P. C. (in review). Prediction can be safely used as a proxy for explanation in causally consistent Bayesian generalized linear models. ArXiv preprint. Preprint Code & Data\nScholz M. & Bürkner P. C. (in review). Posterior accuracy and calibration under misspecification in Bayesian generalized linear models. ArXiv preprint. Preprint Code & Data\nBürkner P. C., Scholz M., & Radev S. T. (2023). Some models are useful, but how do we know which ones? Towards a unified Bayesian model taxonomy. Statistics Surveys. doi:10.1214/23-SS145 PDF Journal Preprint\n\nSoftware:\n\nbayesim: Simulations for Bayesian models GitHub\nbayeshear: Metrics for evaluating Bayesian models GitHub\nbayesfam: Custom families for brms GitHub"
  },
  {
    "objectID": "projects/index.html#past-projects",
    "href": "projects/index.html#past-projects",
    "title": "Research Projects",
    "section": "Past Projects",
    "text": "Past Projects\n\n\n\n\n\n\nMachine Learning for Bayesian Model Building\n\n\n\n\n\n\n\n\n\n\nThe Bayesian approach to data analysis provides a consistent and flexible way to handle uncertainty in all observations, model parameters, and model structure using probability theory. However, building Bayesian models in a principled way remains a highly complex task requiring a lot of expertise and cognitive resources. In this project, we will develop a machine assisted workflow for building interpretable, robust, and well-predicting Bayesian models. Based on statistical theory, we will develop a framework for simulating realistic data with known modeling challenges. Subsequently, using neural network architectures tuned to the structure of the fitted Bayesian models, machines will be trained on the simulated data to provide automatic model evaluation and modeling recommendations that guide the user through the model building process using interactive visualizations. While leaving the modeling choices up to the user, the machine learns from the user’s decisions to improve its recommendations on the fly.\nOverarching Topics: Machine-Assisted Workflows Model Comparison Uncertainty Quantification\nProject Members: Maximilian Scholz\nFunders: Cluster of Excellence SimTech\nFunding Period: 2021 – 2024\nPublications:\n\nFazio L., Scholz M., & Bürkner P. C. (in review). Generative Bayesian Modeling with Implicit Priors. ArXiv preprint. Preprint Code & Data\nScholz M. & Bürkner P. C. (in review). Prediction can be safely used as a proxy for explanation in causally consistent Bayesian generalized linear models. ArXiv preprint. Preprint Code & Data\nScholz M. & Bürkner P. C. (in review). Posterior accuracy and calibration under misspecification in Bayesian generalized linear models. ArXiv preprint. Preprint Code & Data\nBürkner P. C., Scholz M., & Radev S. T. (2023). Some models are useful, but how do we know which ones? Towards a unified Bayesian model taxonomy. Statistics Surveys. doi:10.1214/23-SS145 PDF Journal Preprint\n\nSoftware:\n\nbayesim: Simulations for Bayesian models GitHub\nbayeshear: Metrics for evaluating Bayesian models GitHub\nbayesfam: Custom families for brms GitHub"
  },
  {
    "objectID": "projects/index.html#real-time-spatio-temporal-data-analysis-for-monitoring-logistics-networks",
    "href": "projects/index.html#real-time-spatio-temporal-data-analysis-for-monitoring-logistics-networks",
    "title": "Research Projects",
    "section": "Real-Time Spatio-Temporal Data Analysis for Monitoring Logistics Networks",
    "text": "Real-Time Spatio-Temporal Data Analysis for Monitoring Logistics Networks\nIn complex logistics and supply chain networks, the acquisition of tracking data representing the flow of entities through the networks has become state of the art. The goal of tracking entities is to improve transparency and predict the state of the network. An important value for operations is the estimated time of arrival of entities at different nodes of the network. The respective business goal determines the requirements for the forecasting procedure: it might be necessary to detect a delay in a container ship transport as early as possible (weeks before the arrival) to be able to send a replacement for urgent parts by air. Or it might be necessary to predict the arrival of trucks within the next hour as accurately as possible to manage the traffic at logistics sites. However, acquiring data is costly in terms of money, energy used by sensors, and required IT infrastructure.\nIn this project, we will develop new methods for predicting arrival times in complex logistics networks (e.g., multi-modal transport networks). Our methods will enable (a) the integration of different data types, e.g., event, weather, and tracing data, (b) the ability to cope with changes in the underlying logistics network in real-time, and (c) the ability to communicate uncertainty in predictions, especially in case of tracing data or weather forecasts of limited reliability.\nThis project is part of the Collaborative Research Center 391 funded by the German Research Foundation.\nOverarching Topics: Amortized Inference Uncertainty Quantification\nProject Members: Svenja Jedhoff\nFunders: German Research Foundation (DFG) TU Dortmund University\nFunding Period: 2024 – 2028"
  },
  {
    "objectID": "projects/index.html#abi-logistics",
    "href": "projects/index.html#abi-logistics",
    "title": "Research Projects",
    "section": "Real-Time Spatio-Temporal Data Analysis for Monitoring Logistics Networks",
    "text": "Real-Time Spatio-Temporal Data Analysis for Monitoring Logistics Networks\nIn complex logistics and supply chain networks, the acquisition of tracking data representing the flow of entities through the networks has become state of the art. The goal of tracking entities is to improve transparency and predict the state of the network. An important value for operations is the estimated time of arrival of entities at different nodes of the network. The respective business goal determines the requirements for the forecasting procedure: it might be necessary to detect a delay in a container ship transport as early as possible (weeks before the arrival) to be able to send a replacement for urgent parts by air. Or it might be necessary to predict the arrival of trucks within the next hour as accurately as possible to manage the traffic at logistics sites. However, acquiring data is costly in terms of money, energy used by sensors, and required IT infrastructure.\nIn this project, we will develop new methods for predicting arrival times in complex logistics networks (e.g., multi-modal transport networks). Our methods will enable (a) the integration of different data types, e.g., event, weather, and tracing data, (b) the ability to cope with changes in the underlying logistics network in real-time, and (c) the ability to communicate uncertainty in predictions, especially in case of tracing data or weather forecasts of limited reliability.\nThis project is part of the Collaborative Research Center 391 funded by the German Research Foundation.\nOverarching Topics: Amortized Inference Uncertainty Quantification\nProject Members: Svenja Jedhoff\nFunders: German Research Foundation (DFG) TU Dortmund University\nFunding Period: 2024 – 2028"
  }
]